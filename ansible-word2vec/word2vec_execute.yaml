---
- hosts: word2vec
  become: yes
  become_user: hadoop
  tasks:
    - name: setup hdfs folders
      command: "{{ item }} chdir=/opt/word2vec/crawldb"
      with_items:
      - /opt/hadoop/bin/hdfs dfs -rm -r -f /word2vec
      - /opt/hadoop/bin/hdfs dfs -mkdir /word2vec
      - /opt/hadoop/bin/hdfs dfs -mkdir /word2vec/crawldb
      - /opt/hadoop/bin/hdfs dfs -put /opt/word2vec/data_process/relationstest.csv /word2vec/
      - /opt/hadoop/bin/hdfs dfs -copyFromLocal /opt/word2vec/crawldb /word2vec/
      become: yes
      become_user: hadoop
      become_method: sudo
      tags:
        - clean-hadoop
    - debug: var=ansible_default_ipv4.address
    - name: run spark job on training data set
      command: /opt/word2vec/data_process/create-word2vec-model.sh
      environment:
        PYTHONPATH: $SPARK_HOME/python:$SPARK_HOME/python/lib/py4j-0.9-src.zip:$PYTHONPATH
      tags:
        - create-word2vec-model
    - name: run spark job to create model
      command: /opt/word2vec/data_process/use_word2vec_model.sh
      environment:
        PYTHONPATH: $SPARK_HOME/python:$SPARK_HOME/python/lib/py4j-0.9-src.zip:$PYTHONPATH
      tags:
        - use-word2vec-model
    - name: run spark job to find synonyms
      command: /opt/word2vec/data_process/find_relations.sh
      environment:
        PYTHONPATH: $SPARK_HOME/python:$SPARK_HOME/python/lib/py4j-0.9-src.zip:$PYTHONPATH
      tags:
        - find-relations
    - name: Fetch result csv files from remote to local
      synchronize:  src={{ item }} dest=/tmp/word2vec_results mode=pull
      with_items:
        - "/opt/word2vec/data_process/*.csv"
      tags:
        - get-results
