17/04/28 21:08:05 INFO spark.SparkContext: Running Spark version 2.1.0
17/04/28 21:08:05 WARN spark.SparkContext: Support for Java 7 is deprecated as of Spark 2.0.0
17/04/28 21:08:06 INFO spark.SecurityManager: Changing view acls to: hadoop
17/04/28 21:08:06 INFO spark.SecurityManager: Changing modify acls to: hadoop
17/04/28 21:08:06 INFO spark.SecurityManager: Changing view acls groups to: 
17/04/28 21:08:06 INFO spark.SecurityManager: Changing modify acls groups to: 
17/04/28 21:08:06 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(hadoop); groups with view permissions: Set(); users  with modify permissions: Set(hadoop); groups with modify permissions: Set()
17/04/28 21:08:07 INFO util.Utils: Successfully started service 'sparkDriver' on port 40533.
17/04/28 21:08:07 INFO spark.SparkEnv: Registering MapOutputTracker
17/04/28 21:08:07 INFO spark.SparkEnv: Registering BlockManagerMaster
17/04/28 21:08:07 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/04/28 21:08:07 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/04/28 21:08:07 INFO storage.DiskBlockManager: Created local directory at /tmp/blockmgr-d0307c50-38bf-4fc9-8709-6ef2761a631f
17/04/28 21:08:07 INFO memory.MemoryStore: MemoryStore started with capacity 366.3 MB
17/04/28 21:08:07 INFO spark.SparkEnv: Registering OutputCommitCoordinator
17/04/28 21:08:07 INFO util.log: Logging initialized @4390ms
17/04/28 21:08:07 INFO server.Server: jetty-9.2.z-SNAPSHOT
17/04/28 21:08:07 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@326868cc{/jobs,null,AVAILABLE}
17/04/28 21:08:07 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@64b842ee{/jobs/json,null,AVAILABLE}
17/04/28 21:08:07 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7d324aea{/jobs/job,null,AVAILABLE}
17/04/28 21:08:07 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@70d488dc{/jobs/job/json,null,AVAILABLE}
17/04/28 21:08:07 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@11655d63{/stages,null,AVAILABLE}
17/04/28 21:08:07 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@15d61781{/stages/json,null,AVAILABLE}
17/04/28 21:08:07 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1aa1215a{/stages/stage,null,AVAILABLE}
17/04/28 21:08:07 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4894a95e{/stages/stage/json,null,AVAILABLE}
17/04/28 21:08:07 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@17fb7f8c{/stages/pool,null,AVAILABLE}
17/04/28 21:08:07 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@72cca1{/stages/pool/json,null,AVAILABLE}
17/04/28 21:08:07 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@70d85e41{/storage,null,AVAILABLE}
17/04/28 21:08:07 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@d143748{/storage/json,null,AVAILABLE}
17/04/28 21:08:07 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2a395ead{/storage/rdd,null,AVAILABLE}
17/04/28 21:08:07 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1c76c583{/storage/rdd/json,null,AVAILABLE}
17/04/28 21:08:07 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@39a12a0e{/environment,null,AVAILABLE}
17/04/28 21:08:07 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3d01ab1{/environment/json,null,AVAILABLE}
17/04/28 21:08:07 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@53885c6b{/executors,null,AVAILABLE}
17/04/28 21:08:07 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1d6b9fa5{/executors/json,null,AVAILABLE}
17/04/28 21:08:07 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4be18ba{/executors/threadDump,null,AVAILABLE}
17/04/28 21:08:07 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5c495dc4{/executors/threadDump/json,null,AVAILABLE}
17/04/28 21:08:07 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@54ab1e31{/static,null,AVAILABLE}
17/04/28 21:08:07 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2e4b4e64{/,null,AVAILABLE}
17/04/28 21:08:07 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@52079efa{/api,null,AVAILABLE}
17/04/28 21:08:07 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@72565928{/jobs/job/kill,null,AVAILABLE}
17/04/28 21:08:07 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2f78bbd{/stages/stage/kill,null,AVAILABLE}
17/04/28 21:08:07 INFO server.ServerConnector: Started ServerConnector@50f85a5f{HTTP/1.1}{0.0.0.0:4040}
17/04/28 21:08:07 INFO server.Server: Started @4520ms
17/04/28 21:08:07 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.
17/04/28 21:08:07 INFO ui.SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.0.243:4040
17/04/28 21:08:08 INFO client.RMProxy: Connecting to ResourceManager at stack-0060/192.168.0.243:8032
17/04/28 21:08:08 INFO yarn.Client: Requesting a new application from cluster with 1 NodeManagers
17/04/28 21:08:08 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (8192 MB per container)
17/04/28 21:08:08 INFO yarn.Client: Will allocate AM container, with 896 MB memory including 384 MB overhead
17/04/28 21:08:08 INFO yarn.Client: Setting up container launch context for our AM
17/04/28 21:08:08 INFO yarn.Client: Setting up the launch environment for our AM container
17/04/28 21:08:08 INFO yarn.Client: Preparing resources for our AM container
17/04/28 21:08:10 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
17/04/28 21:08:12 INFO yarn.Client: Uploading resource file:/tmp/spark-1f2316cd-228c-4226-9115-22f427af0a07/__spark_libs__4413961739697387005.zip -> hdfs://stack-0060/user/hadoop/.sparkStaging/application_1493187723643_0017/__spark_libs__4413961739697387005.zip
17/04/28 21:08:13 INFO yarn.Client: Uploading resource file:/opt/spark/python/lib/pyspark.zip -> hdfs://stack-0060/user/hadoop/.sparkStaging/application_1493187723643_0017/pyspark.zip
17/04/28 21:08:13 INFO yarn.Client: Uploading resource file:/opt/spark/python/lib/py4j-0.10.4-src.zip -> hdfs://stack-0060/user/hadoop/.sparkStaging/application_1493187723643_0017/py4j-0.10.4-src.zip
17/04/28 21:08:13 INFO yarn.Client: Uploading resource file:/tmp/spark-1f2316cd-228c-4226-9115-22f427af0a07/__spark_conf__6411175988429138494.zip -> hdfs://stack-0060/user/hadoop/.sparkStaging/application_1493187723643_0017/__spark_conf__.zip
17/04/28 21:08:14 INFO spark.SecurityManager: Changing view acls to: hadoop
17/04/28 21:08:14 INFO spark.SecurityManager: Changing modify acls to: hadoop
17/04/28 21:08:14 INFO spark.SecurityManager: Changing view acls groups to: 
17/04/28 21:08:14 INFO spark.SecurityManager: Changing modify acls groups to: 
17/04/28 21:08:14 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(hadoop); groups with view permissions: Set(); users  with modify permissions: Set(hadoop); groups with modify permissions: Set()
17/04/28 21:08:14 INFO yarn.Client: Submitting application application_1493187723643_0017 to ResourceManager
17/04/28 21:08:14 INFO impl.YarnClientImpl: Submitted application application_1493187723643_0017
17/04/28 21:08:14 INFO cluster.SchedulerExtensionServices: Starting Yarn extension services with app application_1493187723643_0017 and attemptId None
17/04/28 21:08:15 INFO yarn.Client: Application report for application_1493187723643_0017 (state: ACCEPTED)
17/04/28 21:08:15 INFO yarn.Client: 
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1493413694081
	 final status: UNDEFINED
	 tracking URL: http://stack-0060:8088/proxy/application_1493187723643_0017/
	 user: hadoop
17/04/28 21:08:16 INFO yarn.Client: Application report for application_1493187723643_0017 (state: ACCEPTED)
17/04/28 21:08:17 INFO yarn.Client: Application report for application_1493187723643_0017 (state: ACCEPTED)
17/04/28 21:08:18 INFO yarn.Client: Application report for application_1493187723643_0017 (state: ACCEPTED)
17/04/28 21:08:18 INFO cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(null)
17/04/28 21:08:18 INFO cluster.YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> stack-0060, PROXY_URI_BASES -> http://stack-0060:8088/proxy/application_1493187723643_0017), /proxy/application_1493187723643_0017
17/04/28 21:08:18 INFO ui.JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
17/04/28 21:08:19 INFO yarn.Client: Application report for application_1493187723643_0017 (state: RUNNING)
17/04/28 21:08:19 INFO yarn.Client: 
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: 192.168.0.243
	 ApplicationMaster RPC port: 0
	 queue: default
	 start time: 1493413694081
	 final status: UNDEFINED
	 tracking URL: http://stack-0060:8088/proxy/application_1493187723643_0017/
	 user: hadoop
17/04/28 21:08:19 INFO cluster.YarnClientSchedulerBackend: Application application_1493187723643_0017 has started running.
17/04/28 21:08:19 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35613.
17/04/28 21:08:19 INFO netty.NettyBlockTransferService: Server created on 192.168.0.243:35613
17/04/28 21:08:19 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/04/28 21:08:19 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.0.243, 35613, None)
17/04/28 21:08:19 INFO storage.BlockManagerMasterEndpoint: Registering block manager 192.168.0.243:35613 with 366.3 MB RAM, BlockManagerId(driver, 192.168.0.243, 35613, None)
17/04/28 21:08:19 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.0.243, 35613, None)
17/04/28 21:08:19 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.0.243, 35613, None)
17/04/28 21:08:19 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1ebadbc6{/metrics/json,null,AVAILABLE}
17/04/28 21:08:23 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(null) (192.168.0.243:59816) with ID 1
17/04/28 21:08:23 INFO storage.BlockManagerMasterEndpoint: Registering block manager stack-0060.local:43606 with 366.3 MB RAM, BlockManagerId(1, stack-0060.local, 43606, None)
17/04/28 21:08:24 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(null) (192.168.0.243:59818) with ID 2
17/04/28 21:08:24 INFO storage.BlockManagerMasterEndpoint: Registering block manager stack-0060.local:47215 with 366.3 MB RAM, BlockManagerId(2, stack-0060.local, 47215, None)
17/04/28 21:08:24 INFO cluster.YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8
17/04/28 21:08:24 INFO internal.SharedState: Warehouse path is 'file:/opt/word2vec/data_process/spark-warehouse/'.
17/04/28 21:08:24 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@d87cc86{/SQL,null,AVAILABLE}
17/04/28 21:08:24 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5af984fb{/SQL/json,null,AVAILABLE}
17/04/28 21:08:24 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6147d90d{/SQL/execution,null,AVAILABLE}
17/04/28 21:08:24 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@297a1349{/SQL/execution/json,null,AVAILABLE}
17/04/28 21:08:24 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4e13498d{/static/sql,null,AVAILABLE}
17/04/28 21:08:24 INFO memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 234.0 KB, free 366.1 MB)
17/04/28 21:08:24 INFO memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.5 KB, free 366.1 MB)
17/04/28 21:08:24 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.0.243:35613 (size: 20.5 KB, free: 366.3 MB)
17/04/28 21:08:24 INFO spark.SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:0
17/04/28 21:08:24 INFO mapred.FileInputFormat: Total input paths to process : 1
17/04/28 21:08:24 INFO spark.SparkContext: Starting job: runJob at PythonRDD.scala:441
17/04/28 21:08:24 INFO scheduler.DAGScheduler: Got job 0 (runJob at PythonRDD.scala:441) with 1 output partitions
17/04/28 21:08:24 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (runJob at PythonRDD.scala:441)
17/04/28 21:08:24 INFO scheduler.DAGScheduler: Parents of final stage: List()
17/04/28 21:08:24 INFO scheduler.DAGScheduler: Missing parents: List()
17/04/28 21:08:25 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (PythonRDD[3] at RDD at PythonRDD.scala:48), which has no missing parents
17/04/28 21:08:25 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 7.0 KB, free 366.0 MB)
17/04/28 21:08:25 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.2 KB, free 366.0 MB)
17/04/28 21:08:25 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.0.243:35613 (size: 4.2 KB, free: 366.3 MB)
17/04/28 21:08:25 INFO spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:996
17/04/28 21:08:25 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (PythonRDD[3] at RDD at PythonRDD.scala:48)
17/04/28 21:08:25 INFO cluster.YarnScheduler: Adding task set 0.0 with 1 tasks
17/04/28 21:08:25 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, stack-0060.local, executor 1, partition 0, NODE_LOCAL, 5938 bytes)
17/04/28 21:08:25 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on stack-0060.local:43606 (size: 4.2 KB, free: 366.3 MB)
17/04/28 21:08:25 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on stack-0060.local:43606 (size: 20.5 KB, free: 366.3 MB)
17/04/28 21:08:27 INFO storage.BlockManagerInfo: Added rdd_2_0 in memory on stack-0060.local:43606 (size: 3.7 MB, free: 362.5 MB)
17/04/28 21:08:28 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 2941 ms on stack-0060.local (executor 1) (1/1)
17/04/28 21:08:28 INFO cluster.YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/04/28 21:08:28 INFO scheduler.DAGScheduler: ResultStage 0 (runJob at PythonRDD.scala:441) finished in 2.957 s
17/04/28 21:08:28 INFO scheduler.DAGScheduler: Job 0 finished: runJob at PythonRDD.scala:441, took 3.063098 s
17/04/28 21:08:30 INFO codegen.CodeGenerator: Code generated in 398.118375 ms
=========tokDF============
17/04/28 21:08:30 INFO spark.SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
17/04/28 21:08:30 INFO scheduler.DAGScheduler: Got job 1 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/04/28 21:08:30 INFO scheduler.DAGScheduler: Final stage: ResultStage 1 (showString at NativeMethodAccessorImpl.java:0)
17/04/28 21:08:30 INFO scheduler.DAGScheduler: Parents of final stage: List()
17/04/28 21:08:30 INFO scheduler.DAGScheduler: Missing parents: List()
17/04/28 21:08:30 INFO scheduler.DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[14] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
17/04/28 21:08:30 INFO memory.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 23.9 KB, free 366.0 MB)
17/04/28 21:08:30 INFO memory.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 11.9 KB, free 366.0 MB)
17/04/28 21:08:30 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.0.243:35613 (size: 11.9 KB, free: 366.3 MB)
17/04/28 21:08:30 INFO spark.SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:996
17/04/28 21:08:30 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[14] at showString at NativeMethodAccessorImpl.java:0)
17/04/28 21:08:30 INFO cluster.YarnScheduler: Adding task set 1.0 with 1 tasks
17/04/28 21:08:30 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, stack-0060.local, executor 1, partition 0, PROCESS_LOCAL, 5967 bytes)
17/04/28 21:08:30 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on stack-0060.local:43606 (size: 11.9 KB, free: 362.5 MB)
17/04/28 21:08:32 INFO storage.BlockManagerInfo: Added rdd_9_0 in memory on stack-0060.local:43606 (size: 3.6 MB, free: 358.9 MB)
17/04/28 21:08:33 INFO storage.BlockManagerInfo: Added rdd_12_0 in memory on stack-0060.local:43606 (size: 13.9 MB, free: 345.0 MB)
17/04/28 21:08:33 INFO scheduler.DAGScheduler: ResultStage 1 (showString at NativeMethodAccessorImpl.java:0) finished in 3.477 s
17/04/28 21:08:33 INFO scheduler.DAGScheduler: Job 1 finished: showString at NativeMethodAccessorImpl.java:0, took 3.510742 s
17/04/28 21:08:33 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 3474 ms on stack-0060.local (executor 1) (1/1)
17/04/28 21:08:33 INFO cluster.YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/04/28 21:08:33 INFO codegen.CodeGenerator: Code generated in 48.641699 ms
+--------------------+--------------------+
|                text|               words|
+--------------------+--------------------+
|Andre Dwayne Russ...|[andre, dwayne, r...|
|                    |                  []|
|                    |                  []|
|   Style of Batti...|[, , , style, of,...|
|Russell has a uni...|[russell, has, a,...|
|                    |                  []|
|                    |                  []|
|   Domestic caree...|[, , , domestic, ...|
|In the season 201...|[in, the, season,...|
|                    |                  []|
|                    |                  []|
|   International ...|[, , , internatio...|
|A fast bowling al...|[a, fast, bowling...|
|He made his ODI d...|[he, made, his, o...|
|After a poor home...|[after, a, poor, ...|
|                    |                  []|
|                    |                  []|
|   Indian Premier...|[, , , indian, pr...|
|During the 2012 I...|[during, the, 201...|
|On 21 September 2...|[on, 21, septembe...|
+--------------------+--------------------+
only showing top 20 rows

17/04/28 21:08:33 INFO spark.SparkContext: Starting job: collect at Word2Vec.scala:195
17/04/28 21:08:34 INFO scheduler.DAGScheduler: Registering RDD 20 (map at Word2Vec.scala:186)
17/04/28 21:08:34 INFO scheduler.DAGScheduler: Got job 2 (collect at Word2Vec.scala:195) with 2 output partitions
17/04/28 21:08:34 INFO scheduler.DAGScheduler: Final stage: ResultStage 3 (collect at Word2Vec.scala:195)
17/04/28 21:08:34 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
17/04/28 21:08:34 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 2)
17/04/28 21:08:34 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[20] at map at Word2Vec.scala:186), which has no missing parents
17/04/28 21:08:34 INFO memory.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 27.5 KB, free 366.0 MB)
17/04/28 21:08:34 INFO memory.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 13.6 KB, free 366.0 MB)
17/04/28 21:08:34 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 192.168.0.243:35613 (size: 13.6 KB, free: 366.3 MB)
17/04/28 21:08:34 INFO spark.SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:996
17/04/28 21:08:34 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[20] at map at Word2Vec.scala:186)
17/04/28 21:08:34 INFO cluster.YarnScheduler: Adding task set 2.0 with 2 tasks
17/04/28 21:08:34 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, stack-0060.local, executor 1, partition 0, PROCESS_LOCAL, 6012 bytes)
17/04/28 21:08:34 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 2.0 (TID 3, stack-0060.local, executor 2, partition 1, NODE_LOCAL, 6012 bytes)
17/04/28 21:08:34 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on stack-0060.local:43606 (size: 13.6 KB, free: 345.0 MB)
17/04/28 21:08:34 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on stack-0060.local:47215 (size: 13.6 KB, free: 366.3 MB)
17/04/28 21:08:34 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on stack-0060.local:47215 (size: 20.5 KB, free: 366.3 MB)
17/04/28 21:08:36 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 1817 ms on stack-0060.local (executor 1) (1/2)
17/04/28 21:08:37 INFO storage.BlockManagerInfo: Added rdd_2_1 in memory on stack-0060.local:47215 (size: 3.7 MB, free: 362.5 MB)
17/04/28 21:08:38 INFO storage.BlockManagerInfo: Added rdd_9_1 in memory on stack-0060.local:47215 (size: 3.6 MB, free: 358.9 MB)
17/04/28 21:08:40 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Disabling executor 2.
17/04/28 21:08:40 INFO scheduler.DAGScheduler: Executor lost: 2 (epoch 0)
17/04/28 21:08:40 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 2 from BlockManagerMaster.
17/04/28 21:08:40 INFO storage.BlockManagerMasterEndpoint: Removing block manager BlockManagerId(2, stack-0060.local, 47215, None)
17/04/28 21:08:40 INFO storage.BlockManagerMaster: Removed 2 successfully in removeExecutor
17/04/28 21:08:40 INFO scheduler.DAGScheduler: Shuffle files lost for executor: 2 (epoch 0)
17/04/28 21:08:40 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Container marked as failed: container_1493187723643_0017_01_000003 on host: stack-0060.local. Exit status: 1. Diagnostics: Exception from container-launch.
Container id: container_1493187723643_0017_01_000003
Exit code: 1
Stack trace: ExitCodeException exitCode=1: 
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:545)
	at org.apache.hadoop.util.Shell.run(Shell.java:456)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:722)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:211)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)


Container exited with a non-zero exit code 1

17/04/28 21:08:40 ERROR cluster.YarnScheduler: Lost executor 2 on stack-0060.local: Container marked as failed: container_1493187723643_0017_01_000003 on host: stack-0060.local. Exit status: 1. Diagnostics: Exception from container-launch.
Container id: container_1493187723643_0017_01_000003
Exit code: 1
Stack trace: ExitCodeException exitCode=1: 
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:545)
	at org.apache.hadoop.util.Shell.run(Shell.java:456)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:722)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:211)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)


Container exited with a non-zero exit code 1

17/04/28 21:08:40 WARN scheduler.TaskSetManager: Lost task 1.0 in stage 2.0 (TID 3, stack-0060.local, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container marked as failed: container_1493187723643_0017_01_000003 on host: stack-0060.local. Exit status: 1. Diagnostics: Exception from container-launch.
Container id: container_1493187723643_0017_01_000003
Exit code: 1
Stack trace: ExitCodeException exitCode=1: 
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:545)
	at org.apache.hadoop.util.Shell.run(Shell.java:456)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:722)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:211)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)


Container exited with a non-zero exit code 1

17/04/28 21:08:40 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 2 from BlockManagerMaster.
17/04/28 21:08:40 INFO storage.BlockManagerMaster: Removal of executor 2 requested
17/04/28 21:08:40 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asked to remove non-existent executor 2
17/04/28 21:08:41 INFO scheduler.TaskSetManager: Starting task 1.1 in stage 2.0 (TID 4, stack-0060.local, executor 1, partition 1, NODE_LOCAL, 6012 bytes)
17/04/28 21:08:41 INFO storage.BlockManagerInfo: Added rdd_2_1 in memory on stack-0060.local:43606 (size: 3.7 MB, free: 341.2 MB)
17/04/28 21:08:42 INFO storage.BlockManagerInfo: Added rdd_9_1 in memory on stack-0060.local:43606 (size: 3.6 MB, free: 337.6 MB)
17/04/28 21:08:42 INFO storage.BlockManagerInfo: Added rdd_12_1 in memory on stack-0060.local:43606 (size: 13.9 MB, free: 323.8 MB)
17/04/28 21:08:43 INFO scheduler.DAGScheduler: ShuffleMapStage 2 (map at Word2Vec.scala:186) finished in 9.121 s
17/04/28 21:08:43 INFO scheduler.TaskSetManager: Finished task 1.1 in stage 2.0 (TID 4) in 2232 ms on stack-0060.local (executor 1) (2/2)
17/04/28 21:08:43 INFO cluster.YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/04/28 21:08:43 INFO scheduler.DAGScheduler: looking for newly runnable stages
17/04/28 21:08:43 INFO scheduler.DAGScheduler: running: Set()
17/04/28 21:08:43 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 3)
17/04/28 21:08:43 INFO scheduler.DAGScheduler: failed: Set()
17/04/28 21:08:43 INFO scheduler.DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[23] at map at Word2Vec.scala:189), which has no missing parents
17/04/28 21:08:43 INFO memory.MemoryStore: Block broadcast_4 stored as values in memory (estimated size 4.8 KB, free 366.0 MB)
17/04/28 21:08:43 INFO memory.MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.6 KB, free 366.0 MB)
17/04/28 21:08:43 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on 192.168.0.243:35613 (size: 2.6 KB, free: 366.2 MB)
17/04/28 21:08:43 INFO spark.SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:996
17/04/28 21:08:43 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from ResultStage 3 (MapPartitionsRDD[23] at map at Word2Vec.scala:189)
17/04/28 21:08:43 INFO cluster.YarnScheduler: Adding task set 3.0 with 2 tasks
17/04/28 21:08:43 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 3.0 (TID 5, stack-0060.local, executor 1, partition 0, NODE_LOCAL, 5762 bytes)
17/04/28 21:08:43 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on stack-0060.local:43606 (size: 2.6 KB, free: 323.7 MB)
17/04/28 21:08:43 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 192.168.0.243:59816
17/04/28 21:08:43 INFO spark.MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 159 bytes
17/04/28 21:08:44 INFO storage.BlockManagerInfo: Added taskresult_5 in memory on stack-0060.local:43606 (size: 3.6 MB, free: 320.1 MB)
17/04/28 21:08:44 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 3.0 (TID 6, stack-0060.local, executor 1, partition 1, NODE_LOCAL, 5762 bytes)
17/04/28 21:08:44 INFO client.TransportClientFactory: Successfully created connection to stack-0060.local/192.168.0.243:43606 after 6 ms (0 ms spent in bootstraps)
17/04/28 21:08:44 INFO spark.ContextCleaner: Cleaned accumulator 54
17/04/28 21:08:44 INFO storage.BlockManagerInfo: Removed broadcast_2_piece0 on 192.168.0.243:35613 in memory (size: 11.9 KB, free: 366.3 MB)
17/04/28 21:08:44 INFO storage.BlockManagerInfo: Removed broadcast_2_piece0 on stack-0060.local:43606 in memory (size: 11.9 KB, free: 320.1 MB)
17/04/28 21:08:44 INFO storage.BlockManagerInfo: Removed broadcast_3_piece0 on 192.168.0.243:35613 in memory (size: 13.6 KB, free: 366.3 MB)
17/04/28 21:08:44 INFO storage.BlockManagerInfo: Removed broadcast_3_piece0 on stack-0060.local:43606 in memory (size: 13.6 KB, free: 320.1 MB)
17/04/28 21:08:44 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 3.0 (TID 5) in 1089 ms on stack-0060.local (executor 1) (1/2)
17/04/28 21:08:44 INFO storage.BlockManagerInfo: Removed taskresult_5 on stack-0060.local:43606 in memory (size: 3.6 MB, free: 323.8 MB)
17/04/28 21:08:44 INFO storage.BlockManagerInfo: Added taskresult_6 in memory on stack-0060.local:43606 (size: 3.6 MB, free: 320.1 MB)
17/04/28 21:08:44 INFO scheduler.DAGScheduler: ResultStage 3 (collect at Word2Vec.scala:195) finished in 1.217 s
17/04/28 21:08:44 INFO scheduler.DAGScheduler: Job 2 finished: collect at Word2Vec.scala:195, took 10.607137 s
17/04/28 21:08:44 INFO storage.BlockManagerInfo: Removed taskresult_6 on stack-0060.local:43606 in memory (size: 3.6 MB, free: 323.8 MB)
17/04/28 21:08:44 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 3.0 (TID 6) in 512 ms on stack-0060.local (executor 1) (2/2)
17/04/28 21:08:44 INFO cluster.YarnScheduler: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/04/28 21:08:44 INFO feature.Word2Vec: vocabSize = 20839, trainWordsCount = 2248813
17/04/28 21:08:44 INFO memory.MemoryStore: Block broadcast_5 stored as values in memory (estimated size 3.9 KB, free 366.0 MB)
17/04/28 21:08:44 INFO memory.MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.0 KB, free 366.0 MB)
17/04/28 21:08:44 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on 192.168.0.243:35613 (size: 4.0 KB, free: 366.3 MB)
17/04/28 21:08:44 INFO spark.SparkContext: Created broadcast 5 from broadcast at Word2Vec.scala:314
17/04/28 21:08:44 INFO memory.MemoryStore: Block broadcast_6 stored as values in memory (estimated size 8.8 MB, free 357.2 MB)
17/04/28 21:08:44 INFO memory.MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 829.6 KB, free 356.4 MB)
17/04/28 21:08:44 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on 192.168.0.243:35613 (size: 829.6 KB, free: 365.5 MB)
17/04/28 21:08:44 INFO spark.SparkContext: Created broadcast 6 from broadcast at Word2Vec.scala:315
17/04/28 21:08:44 INFO memory.MemoryStore: Block broadcast_7 stored as values in memory (estimated size 1845.5 KB, free 354.6 MB)
17/04/28 21:08:45 INFO memory.MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 237.7 KB, free 354.4 MB)
17/04/28 21:08:45 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on 192.168.0.243:35613 (size: 237.7 KB, free: 365.2 MB)
17/04/28 21:08:45 INFO spark.SparkContext: Created broadcast 7 from broadcast at Word2Vec.scala:316
17/04/28 21:08:45 INFO memory.MemoryStore: Block broadcast_8 stored as values in memory (estimated size 7.9 MB, free 346.4 MB)
17/04/28 21:08:45 INFO memory.MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 4.0 MB, free 342.4 MB)
17/04/28 21:08:45 INFO storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on 192.168.0.243:35613 (size: 4.0 MB, free: 361.2 MB)
17/04/28 21:08:45 INFO memory.MemoryStore: Block broadcast_8_piece1 stored as bytes in memory (estimated size 4.0 MB, free 338.5 MB)
17/04/28 21:08:45 INFO storage.BlockManagerInfo: Added broadcast_8_piece1 in memory on 192.168.0.243:35613 (size: 4.0 MB, free: 357.3 MB)
17/04/28 21:08:45 INFO spark.SparkContext: Created broadcast 8 from broadcast at Word2Vec.scala:344
17/04/28 21:08:45 INFO memory.MemoryStore: Block broadcast_9 stored as values in memory (estimated size 7.9 MB, free 330.5 MB)
17/04/28 21:08:45 INFO memory.MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 39.8 KB, free 330.5 MB)
17/04/28 21:08:45 INFO storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on 192.168.0.243:35613 (size: 39.8 KB, free: 357.2 MB)
17/04/28 21:08:45 INFO spark.SparkContext: Created broadcast 9 from broadcast at Word2Vec.scala:345
17/04/28 21:08:45 INFO spark.SparkContext: Starting job: collect at Word2Vec.scala:423
17/04/28 21:08:45 INFO scheduler.DAGScheduler: Registering RDD 25 (repartition at Word2Vec.scala:329)
17/04/28 21:08:45 INFO scheduler.DAGScheduler: Registering RDD 29 (mapPartitionsWithIndex at Word2Vec.scala:346)
17/04/28 21:08:45 INFO scheduler.DAGScheduler: Got job 3 (collect at Word2Vec.scala:423) with 1 output partitions
17/04/28 21:08:45 INFO scheduler.DAGScheduler: Final stage: ResultStage 6 (collect at Word2Vec.scala:423)
17/04/28 21:08:45 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
17/04/28 21:08:45 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 5)
17/04/28 21:08:45 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[25] at repartition at Word2Vec.scala:329), which has no missing parents
17/04/28 21:08:45 INFO memory.MemoryStore: Block broadcast_10 stored as values in memory (estimated size 28.3 KB, free 330.4 MB)
17/04/28 21:08:45 INFO memory.MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 13.9 KB, free 330.4 MB)
17/04/28 21:08:45 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on 192.168.0.243:35613 (size: 13.9 KB, free: 357.2 MB)
17/04/28 21:08:45 INFO spark.SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:996
17/04/28 21:08:45 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[25] at repartition at Word2Vec.scala:329)
17/04/28 21:08:45 INFO cluster.YarnScheduler: Adding task set 4.0 with 2 tasks
17/04/28 21:08:45 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 4.0 (TID 7, stack-0060.local, executor 1, partition 0, PROCESS_LOCAL, 6012 bytes)
17/04/28 21:08:45 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on stack-0060.local:43606 (size: 13.9 KB, free: 323.8 MB)
17/04/28 21:08:45 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on stack-0060.local:43606 (size: 237.7 KB, free: 323.5 MB)
17/04/28 21:08:46 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 4.0 (TID 8, stack-0060.local, executor 1, partition 1, PROCESS_LOCAL, 6012 bytes)
17/04/28 21:08:46 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 4.0 (TID 7) in 1487 ms on stack-0060.local (executor 1) (1/2)
17/04/28 21:08:47 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 4.0 (TID 8) in 740 ms on stack-0060.local (executor 1) (2/2)
17/04/28 21:08:47 INFO cluster.YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool 
17/04/28 21:08:47 INFO scheduler.DAGScheduler: ShuffleMapStage 4 (repartition at Word2Vec.scala:329) finished in 2.224 s
17/04/28 21:08:47 INFO scheduler.DAGScheduler: looking for newly runnable stages
17/04/28 21:08:47 INFO scheduler.DAGScheduler: running: Set()
17/04/28 21:08:47 INFO scheduler.DAGScheduler: waiting: Set(ShuffleMapStage 5, ResultStage 6)
17/04/28 21:08:47 INFO scheduler.DAGScheduler: failed: Set()
17/04/28 21:08:47 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[29] at mapPartitionsWithIndex at Word2Vec.scala:346), which has no missing parents
17/04/28 21:08:47 INFO memory.MemoryStore: Block broadcast_11 stored as values in memory (estimated size 6.3 KB, free 330.4 MB)
17/04/28 21:08:47 INFO memory.MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 3.4 KB, free 330.4 MB)
17/04/28 21:08:47 INFO storage.BlockManagerInfo: Added broadcast_11_piece0 in memory on 192.168.0.243:35613 (size: 3.4 KB, free: 357.2 MB)
17/04/28 21:08:47 INFO spark.SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:996
17/04/28 21:08:47 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[29] at mapPartitionsWithIndex at Word2Vec.scala:346)
17/04/28 21:08:47 INFO cluster.YarnScheduler: Adding task set 5.0 with 1 tasks
17/04/28 21:08:47 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 5.0 (TID 9, stack-0060.local, executor 1, partition 0, NODE_LOCAL, 6027 bytes)
17/04/28 21:08:47 INFO storage.BlockManagerInfo: Added broadcast_11_piece0 in memory on stack-0060.local:43606 (size: 3.4 KB, free: 323.5 MB)
17/04/28 21:08:47 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 192.168.0.243:59816
17/04/28 21:08:47 INFO spark.MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 156 bytes
17/04/28 21:08:48 INFO storage.BlockManagerInfo: Added rdd_28_0 in memory on stack-0060.local:43606 (size: 9.8 MB, free: 313.7 MB)
17/04/28 21:08:48 INFO storage.BlockManagerInfo: Added broadcast_8_piece1 in memory on stack-0060.local:43606 (size: 4.0 MB, free: 309.7 MB)
17/04/28 21:08:48 INFO storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on stack-0060.local:43606 (size: 4.0 MB, free: 305.7 MB)
17/04/28 21:08:48 INFO storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on stack-0060.local:43606 (size: 39.8 KB, free: 305.7 MB)
17/04/28 21:08:48 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on stack-0060.local:43606 (size: 829.6 KB, free: 304.9 MB)
17/04/28 21:08:48 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on stack-0060.local:43606 (size: 4.0 KB, free: 304.9 MB)
17/04/28 21:08:50 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(null) (192.168.0.243:59837) with ID 3
17/04/28 21:08:50 INFO storage.BlockManagerMasterEndpoint: Registering block manager stack-0060.local:41283 with 366.3 MB RAM, BlockManagerId(3, stack-0060.local, 41283, None)
17/04/28 21:09:27 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 5.0 (TID 9) in 39912 ms on stack-0060.local (executor 1) (1/1)
17/04/28 21:09:27 INFO cluster.YarnScheduler: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/04/28 21:09:27 INFO scheduler.DAGScheduler: ShuffleMapStage 5 (mapPartitionsWithIndex at Word2Vec.scala:346) finished in 39.912 s
17/04/28 21:09:27 INFO scheduler.DAGScheduler: looking for newly runnable stages
17/04/28 21:09:27 INFO scheduler.DAGScheduler: running: Set()
17/04/28 21:09:27 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 6)
17/04/28 21:09:27 INFO scheduler.DAGScheduler: failed: Set()
17/04/28 21:09:27 INFO scheduler.DAGScheduler: Submitting ResultStage 6 (ShuffledRDD[30] at reduceByKey at Word2Vec.scala:420), which has no missing parents
17/04/28 21:09:27 INFO memory.MemoryStore: Block broadcast_12 stored as values in memory (estimated size 4.4 KB, free 330.4 MB)
17/04/28 21:09:27 INFO memory.MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 2.4 KB, free 330.4 MB)
17/04/28 21:09:27 INFO storage.BlockManagerInfo: Added broadcast_12_piece0 in memory on 192.168.0.243:35613 (size: 2.4 KB, free: 357.2 MB)
17/04/28 21:09:27 INFO spark.SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:996
17/04/28 21:09:27 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (ShuffledRDD[30] at reduceByKey at Word2Vec.scala:420)
17/04/28 21:09:27 INFO cluster.YarnScheduler: Adding task set 6.0 with 1 tasks
17/04/28 21:09:27 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 6.0 (TID 10, stack-0060.local, executor 3, partition 0, NODE_LOCAL, 5762 bytes)
17/04/28 21:09:27 INFO storage.BlockManagerInfo: Added broadcast_12_piece0 in memory on stack-0060.local:41283 (size: 2.4 KB, free: 366.3 MB)
17/04/28 21:09:28 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 192.168.0.243:59837
17/04/28 21:09:28 INFO spark.MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 147 bytes
17/04/28 21:09:30 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Disabling executor 3.
17/04/28 21:09:30 INFO scheduler.DAGScheduler: Executor lost: 3 (epoch 4)
17/04/28 21:09:30 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 3 from BlockManagerMaster.
17/04/28 21:09:30 INFO storage.BlockManagerMasterEndpoint: Removing block manager BlockManagerId(3, stack-0060.local, 41283, None)
17/04/28 21:09:30 INFO storage.BlockManagerMaster: Removed 3 successfully in removeExecutor
17/04/28 21:09:30 INFO scheduler.DAGScheduler: Shuffle files lost for executor: 3 (epoch 4)
17/04/28 21:09:31 ERROR cluster.YarnScheduler: Lost executor 3 on stack-0060.local: Container marked as failed: container_1493187723643_0017_01_000005 on host: stack-0060.local. Exit status: 1. Diagnostics: Exception from container-launch.
Container id: container_1493187723643_0017_01_000005
Exit code: 1
Stack trace: ExitCodeException exitCode=1: 
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:545)
	at org.apache.hadoop.util.Shell.run(Shell.java:456)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:722)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:211)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)


Container exited with a non-zero exit code 1

17/04/28 21:09:31 WARN scheduler.TaskSetManager: Lost task 0.0 in stage 6.0 (TID 10, stack-0060.local, executor 3): ExecutorLostFailure (executor 3 exited caused by one of the running tasks) Reason: Container marked as failed: container_1493187723643_0017_01_000005 on host: stack-0060.local. Exit status: 1. Diagnostics: Exception from container-launch.
Container id: container_1493187723643_0017_01_000005
Exit code: 1
Stack trace: ExitCodeException exitCode=1: 
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:545)
	at org.apache.hadoop.util.Shell.run(Shell.java:456)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:722)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:211)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)


Container exited with a non-zero exit code 1

17/04/28 21:09:31 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Container marked as failed: container_1493187723643_0017_01_000005 on host: stack-0060.local. Exit status: 1. Diagnostics: Exception from container-launch.
Container id: container_1493187723643_0017_01_000005
Exit code: 1
Stack trace: ExitCodeException exitCode=1: 
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:545)
	at org.apache.hadoop.util.Shell.run(Shell.java:456)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:722)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:211)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)


Container exited with a non-zero exit code 1

17/04/28 21:09:31 INFO storage.BlockManagerMaster: Removal of executor 3 requested
17/04/28 21:09:31 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asked to remove non-existent executor 3
17/04/28 21:09:31 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 3 from BlockManagerMaster.
17/04/28 21:09:32 INFO scheduler.TaskSetManager: Starting task 0.1 in stage 6.0 (TID 11, stack-0060.local, executor 1, partition 0, NODE_LOCAL, 5762 bytes)
17/04/28 21:09:32 INFO storage.BlockManagerInfo: Added broadcast_12_piece0 in memory on stack-0060.local:43606 (size: 2.4 KB, free: 304.9 MB)
17/04/28 21:09:32 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 192.168.0.243:59816
17/04/28 21:09:32 INFO spark.MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 147 bytes
17/04/28 21:09:32 INFO storage.BlockManagerInfo: Added taskresult_11 in memory on stack-0060.local:43606 (size: 17.0 MB, free: 287.9 MB)
17/04/28 21:09:32 INFO storage.BlockManagerInfo: Removed taskresult_11 on stack-0060.local:43606 in memory (size: 17.0 MB, free: 304.9 MB)
17/04/28 21:09:32 INFO scheduler.DAGScheduler: ResultStage 6 (collect at Word2Vec.scala:423) finished in 5.079 s
17/04/28 21:09:32 INFO scheduler.DAGScheduler: Job 3 finished: collect at Word2Vec.scala:423, took 47.309190 s
17/04/28 21:09:32 INFO scheduler.TaskSetManager: Finished task 0.1 in stage 6.0 (TID 11) in 520 ms on stack-0060.local (executor 1) (1/1)
17/04/28 21:09:32 INFO cluster.YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool 
17/04/28 21:09:32 INFO broadcast.TorrentBroadcast: Destroying Broadcast(8) (from destroy at Word2Vec.scala:434)
17/04/28 21:09:32 INFO storage.BlockManagerInfo: Removed broadcast_8_piece0 on 192.168.0.243:35613 in memory (size: 4.0 MB, free: 361.2 MB)
17/04/28 21:09:32 INFO broadcast.TorrentBroadcast: Destroying Broadcast(9) (from destroy at Word2Vec.scala:435)
17/04/28 21:09:32 INFO storage.BlockManagerInfo: Removed broadcast_9_piece0 on 192.168.0.243:35613 in memory (size: 39.8 KB, free: 361.3 MB)
17/04/28 21:09:32 INFO storage.BlockManagerInfo: Removed broadcast_8_piece1 on 192.168.0.243:35613 in memory (size: 4.0 MB, free: 365.2 MB)
17/04/28 21:09:32 INFO storage.BlockManagerInfo: Removed broadcast_8_piece0 on stack-0060.local:43606 in memory (size: 4.0 MB, free: 308.9 MB)
17/04/28 21:09:32 INFO rdd.MapPartitionsRDD: Removing RDD 28 from persistence list
17/04/28 21:09:32 INFO storage.BlockManagerInfo: Removed broadcast_9_piece0 on stack-0060.local:43606 in memory (size: 39.8 KB, free: 308.9 MB)
17/04/28 21:09:32 INFO storage.BlockManagerInfo: Removed broadcast_8_piece1 on stack-0060.local:43606 in memory (size: 4.0 MB, free: 322.7 MB)
17/04/28 21:09:32 INFO storage.BlockManager: Removing RDD 28
17/04/28 21:09:32 INFO broadcast.TorrentBroadcast: Destroying Broadcast(5) (from destroy at Word2Vec.scala:438)
17/04/28 21:09:32 INFO storage.BlockManagerInfo: Removed broadcast_5_piece0 on stack-0060.local:43606 in memory (size: 4.0 KB, free: 322.7 MB)
17/04/28 21:09:32 INFO storage.BlockManagerInfo: Removed broadcast_5_piece0 on 192.168.0.243:35613 in memory (size: 4.0 KB, free: 365.2 MB)
17/04/28 21:09:32 INFO broadcast.TorrentBroadcast: Destroying Broadcast(6) (from destroy at Word2Vec.scala:439)
17/04/28 21:09:32 INFO storage.BlockManagerInfo: Removed broadcast_6_piece0 on 192.168.0.243:35613 in memory (size: 829.6 KB, free: 366.0 MB)
17/04/28 21:09:32 INFO storage.BlockManagerInfo: Removed broadcast_6_piece0 on stack-0060.local:43606 in memory (size: 829.6 KB, free: 323.5 MB)
17/04/28 21:09:32 INFO broadcast.TorrentBroadcast: Destroying Broadcast(7) (from destroy at Word2Vec.scala:440)
17/04/28 21:09:32 INFO storage.BlockManagerInfo: Removed broadcast_7_piece0 on 192.168.0.243:35613 in memory (size: 237.7 KB, free: 366.3 MB)
17/04/28 21:09:32 INFO storage.BlockManagerInfo: Removed broadcast_7_piece0 on stack-0060.local:43606 in memory (size: 237.7 KB, free: 323.8 MB)
17/04/28 21:09:33 INFO storage.BlockManagerInfo: Removed broadcast_4_piece0 on 192.168.0.243:35613 in memory (size: 2.6 KB, free: 366.3 MB)
17/04/28 21:09:33 INFO storage.BlockManagerInfo: Removed broadcast_4_piece0 on stack-0060.local:43606 in memory (size: 2.6 KB, free: 323.8 MB)
17/04/28 21:09:33 INFO storage.BlockManagerInfo: Removed broadcast_12_piece0 on 192.168.0.243:35613 in memory (size: 2.4 KB, free: 366.3 MB)
17/04/28 21:09:33 INFO storage.BlockManagerInfo: Removed broadcast_12_piece0 on stack-0060.local:43606 in memory (size: 2.4 KB, free: 323.8 MB)
17/04/28 21:09:33 INFO spark.ContextCleaner: Cleaned shuffle 2
17/04/28 21:09:33 INFO storage.BlockManagerInfo: Removed broadcast_10_piece0 on 192.168.0.243:35613 in memory (size: 13.9 KB, free: 366.3 MB)
17/04/28 21:09:33 INFO storage.BlockManagerInfo: Removed broadcast_10_piece0 on stack-0060.local:43606 in memory (size: 13.9 KB, free: 323.8 MB)
17/04/28 21:09:33 INFO storage.BlockManagerInfo: Removed broadcast_11_piece0 on 192.168.0.243:35613 in memory (size: 3.4 KB, free: 366.3 MB)
17/04/28 21:09:33 INFO storage.BlockManagerInfo: Removed broadcast_11_piece0 on stack-0060.local:43606 in memory (size: 3.4 KB, free: 323.8 MB)
17/04/28 21:09:33 INFO spark.ContextCleaner: Cleaned shuffle 0
17/04/28 21:09:33 INFO storage.BlockManagerInfo: Removed broadcast_1_piece0 on 192.168.0.243:35613 in memory (size: 4.2 KB, free: 366.3 MB)
17/04/28 21:09:33 INFO storage.BlockManagerInfo: Removed broadcast_1_piece0 on stack-0060.local:43606 in memory (size: 4.2 KB, free: 323.8 MB)
17/04/28 21:09:33 WARN netlib.BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
17/04/28 21:09:33 WARN netlib.BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
==========word2vec========
17/04/28 21:09:34 INFO codegen.CodeGenerator: Code generated in 26.367893 ms
17/04/28 21:09:34 INFO codegen.CodeGenerator: Code generated in 11.601235 ms
+---------+--------------------+
|     word|              vector|
+---------+--------------------+
| herself.|[-0.0065592238679...|
| incident|[-0.1484792530536...|
|  serious|[-0.2025406658649...|
|    brink|[-0.0113204242661...|
|  acronym|[-0.0129000917077...|
| youthful|[-0.0167471934109...|
|   comply|[-0.0477469675242...|
|   breaks|[-0.0068767326883...|
|     marr|[-0.0268543455749...|
|forgotten|[-0.0281111467629...|
| precious|[-0.0533168278634...|
|    mario|[-0.0274003446102...|
|   boxers|[-0.0829217359423...|
|dynasties|[-0.1569156199693...|
|     37th|[0.06646686792373...|
|     warg|[0.03288827463984...|
|  sectors|[-0.2086202055215...|
|ascension|[-0.0520467050373...|
|   teresa|[-0.2849634289741...|
|  gandhi.|[0.09030992537736...|
+---------+--------------------+
only showing top 20 rows

17/04/28 21:09:34 INFO codegen.CodeGenerator: Code generated in 6.207196 ms
17/04/28 21:09:34 INFO codegen.CodeGenerator: Code generated in 16.496404 ms
17/04/28 21:09:35 INFO codegen.CodeGenerator: Code generated in 13.443524 ms
17/04/28 21:09:35 INFO spark.SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
17/04/28 21:09:35 INFO scheduler.DAGScheduler: Registering RDD 34 (count at NativeMethodAccessorImpl.java:0)
17/04/28 21:09:35 INFO scheduler.DAGScheduler: Got job 4 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/04/28 21:09:35 INFO scheduler.DAGScheduler: Final stage: ResultStage 8 (count at NativeMethodAccessorImpl.java:0)
17/04/28 21:09:35 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
17/04/28 21:09:35 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 7)
17/04/28 21:09:35 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[34] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
17/04/28 21:09:35 INFO memory.MemoryStore: Block broadcast_13 stored as values in memory (estimated size 7.8 KB, free 366.0 MB)
17/04/28 21:09:35 INFO memory.MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 4.2 KB, free 366.0 MB)
17/04/28 21:09:35 INFO storage.BlockManagerInfo: Added broadcast_13_piece0 in memory on 192.168.0.243:35613 (size: 4.2 KB, free: 366.3 MB)
17/04/28 21:09:35 INFO spark.SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:996
17/04/28 21:09:35 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[34] at count at NativeMethodAccessorImpl.java:0)
17/04/28 21:09:35 INFO cluster.YarnScheduler: Adding task set 7.0 with 2 tasks
17/04/28 21:09:35 WARN scheduler.TaskSetManager: Stage 7 contains a task of very large size (178 KB). The maximum recommended task size is 100 KB.
17/04/28 21:09:35 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 7.0 (TID 12, stack-0060.local, executor 1, partition 0, PROCESS_LOCAL, 183252 bytes)
17/04/28 21:09:35 INFO storage.BlockManagerInfo: Added broadcast_13_piece0 in memory on stack-0060.local:43606 (size: 4.2 KB, free: 323.8 MB)
17/04/28 21:09:35 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 7.0 (TID 13, stack-0060.local, executor 1, partition 1, PROCESS_LOCAL, 183269 bytes)
17/04/28 21:09:35 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 7.0 (TID 12) in 311 ms on stack-0060.local (executor 1) (1/2)
17/04/28 21:09:35 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 7.0 (TID 13) in 53 ms on stack-0060.local (executor 1) (2/2)
17/04/28 21:09:35 INFO cluster.YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool 
17/04/28 21:09:35 INFO scheduler.DAGScheduler: ShuffleMapStage 7 (count at NativeMethodAccessorImpl.java:0) finished in 0.355 s
17/04/28 21:09:35 INFO scheduler.DAGScheduler: looking for newly runnable stages
17/04/28 21:09:35 INFO scheduler.DAGScheduler: running: Set()
17/04/28 21:09:35 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 8)
17/04/28 21:09:35 INFO scheduler.DAGScheduler: failed: Set()
17/04/28 21:09:35 INFO scheduler.DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[37] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
17/04/28 21:09:35 INFO memory.MemoryStore: Block broadcast_14 stored as values in memory (estimated size 7.0 KB, free 366.0 MB)
17/04/28 21:09:35 INFO memory.MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 3.7 KB, free 366.0 MB)
17/04/28 21:09:35 INFO storage.BlockManagerInfo: Added broadcast_14_piece0 in memory on 192.168.0.243:35613 (size: 3.7 KB, free: 366.3 MB)
17/04/28 21:09:35 INFO spark.SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:996
17/04/28 21:09:35 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[37] at count at NativeMethodAccessorImpl.java:0)
17/04/28 21:09:35 INFO cluster.YarnScheduler: Adding task set 8.0 with 1 tasks
17/04/28 21:09:35 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 8.0 (TID 14, stack-0060.local, executor 1, partition 0, NODE_LOCAL, 5896 bytes)
17/04/28 21:09:35 INFO storage.BlockManagerInfo: Added broadcast_14_piece0 in memory on stack-0060.local:43606 (size: 3.7 KB, free: 323.8 MB)
17/04/28 21:09:35 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to 192.168.0.243:59816
17/04/28 21:09:35 INFO spark.MapOutputTrackerMaster: Size of output statuses for shuffle 3 is 156 bytes
17/04/28 21:09:35 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 8.0 (TID 14) in 91 ms on stack-0060.local (executor 1) (1/1)
17/04/28 21:09:35 INFO cluster.YarnScheduler: Removed TaskSet 8.0, whose tasks have all completed, from pool 
17/04/28 21:09:35 INFO scheduler.DAGScheduler: ResultStage 8 (count at NativeMethodAccessorImpl.java:0) finished in 0.093 s
17/04/28 21:09:35 INFO scheduler.DAGScheduler: Job 4 finished: count at NativeMethodAccessorImpl.java:0, took 0.476224 s
17/04/28 21:09:35 INFO codegen.CodeGenerator: Code generated in 12.729311 ms
word2vec size = 20839 
17/04/28 21:09:35 INFO Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
17/04/28 21:09:35 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
17/04/28 21:09:35 INFO Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
17/04/28 21:09:35 INFO Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
17/04/28 21:09:35 INFO Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
17/04/28 21:09:35 INFO spark.SparkContext: Starting job: saveAsTextFile at ReadWrite.scala:275
17/04/28 21:09:35 INFO scheduler.DAGScheduler: Got job 5 (saveAsTextFile at ReadWrite.scala:275) with 1 output partitions
17/04/28 21:09:35 INFO scheduler.DAGScheduler: Final stage: ResultStage 9 (saveAsTextFile at ReadWrite.scala:275)
17/04/28 21:09:35 INFO scheduler.DAGScheduler: Parents of final stage: List()
17/04/28 21:09:35 INFO scheduler.DAGScheduler: Missing parents: List()
17/04/28 21:09:35 INFO scheduler.DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[39] at saveAsTextFile at ReadWrite.scala:275), which has no missing parents
17/04/28 21:09:35 INFO memory.MemoryStore: Block broadcast_15 stored as values in memory (estimated size 64.2 KB, free 366.0 MB)
17/04/28 21:09:35 INFO memory.MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 22.6 KB, free 365.9 MB)
17/04/28 21:09:35 INFO storage.BlockManagerInfo: Added broadcast_15_piece0 in memory on 192.168.0.243:35613 (size: 22.6 KB, free: 366.3 MB)
17/04/28 21:09:35 INFO spark.SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:996
17/04/28 21:09:35 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[39] at saveAsTextFile at ReadWrite.scala:275)
17/04/28 21:09:35 INFO cluster.YarnScheduler: Adding task set 9.0 with 1 tasks
17/04/28 21:09:35 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 9.0 (TID 15, stack-0060.local, executor 1, partition 0, PROCESS_LOCAL, 6316 bytes)
17/04/28 21:09:35 INFO storage.BlockManagerInfo: Added broadcast_15_piece0 in memory on stack-0060.local:43606 (size: 22.6 KB, free: 323.7 MB)
17/04/28 21:09:36 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 9.0 (TID 15) in 444 ms on stack-0060.local (executor 1) (1/1)
17/04/28 21:09:36 INFO cluster.YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool 
17/04/28 21:09:36 INFO scheduler.DAGScheduler: ResultStage 9 (saveAsTextFile at ReadWrite.scala:275) finished in 0.445 s
17/04/28 21:09:36 INFO scheduler.DAGScheduler: Job 5 finished: saveAsTextFile at ReadWrite.scala:275, took 0.512789 s
17/04/28 21:09:36 INFO parquet.ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
17/04/28 21:09:37 INFO codegen.CodeGenerator: Code generated in 49.25829 ms
17/04/28 21:09:37 INFO datasources.SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/04/28 21:09:37 INFO datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/04/28 21:09:37 INFO spark.SparkContext: Starting job: parquet at Word2Vec.scala:314
17/04/28 21:09:37 INFO scheduler.DAGScheduler: Registering RDD 42 (parquet at Word2Vec.scala:314)
17/04/28 21:09:37 INFO scheduler.DAGScheduler: Got job 6 (parquet at Word2Vec.scala:314) with 1 output partitions
17/04/28 21:09:37 INFO scheduler.DAGScheduler: Final stage: ResultStage 11 (parquet at Word2Vec.scala:314)
17/04/28 21:09:37 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
17/04/28 21:09:37 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 10)
17/04/28 21:09:37 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[42] at parquet at Word2Vec.scala:314), which has no missing parents
17/04/28 21:09:37 INFO memory.MemoryStore: Block broadcast_16 stored as values in memory (estimated size 5.0 KB, free 365.9 MB)
17/04/28 21:09:37 INFO memory.MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 3.0 KB, free 365.9 MB)
17/04/28 21:09:37 INFO storage.BlockManagerInfo: Added broadcast_16_piece0 in memory on 192.168.0.243:35613 (size: 3.0 KB, free: 366.2 MB)
17/04/28 21:09:37 INFO spark.SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:996
17/04/28 21:09:37 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[42] at parquet at Word2Vec.scala:314)
17/04/28 21:09:37 INFO cluster.YarnScheduler: Adding task set 10.0 with 1 tasks
17/04/28 21:09:37 INFO spark.ContextCleaner: Cleaned accumulator 464
17/04/28 21:09:37 INFO spark.ContextCleaner: Cleaned accumulator 465
17/04/28 21:09:37 INFO spark.ContextCleaner: Cleaned accumulator 466
17/04/28 21:09:37 INFO spark.ContextCleaner: Cleaned accumulator 467
17/04/28 21:09:37 INFO spark.ContextCleaner: Cleaned accumulator 468
17/04/28 21:09:37 INFO spark.ContextCleaner: Cleaned accumulator 469
17/04/28 21:09:37 INFO spark.ContextCleaner: Cleaned accumulator 470
17/04/28 21:09:37 INFO spark.ContextCleaner: Cleaned accumulator 471
17/04/28 21:09:37 INFO spark.ContextCleaner: Cleaned accumulator 472
17/04/28 21:09:37 INFO spark.ContextCleaner: Cleaned accumulator 473
17/04/28 21:09:37 INFO spark.ContextCleaner: Cleaned accumulator 474
17/04/28 21:09:37 INFO spark.ContextCleaner: Cleaned accumulator 475
17/04/28 21:09:37 INFO spark.ContextCleaner: Cleaned accumulator 476
17/04/28 21:09:37 INFO spark.ContextCleaner: Cleaned accumulator 477
17/04/28 21:09:37 INFO spark.ContextCleaner: Cleaned shuffle 3
17/04/28 21:09:37 INFO storage.BlockManagerInfo: Removed broadcast_13_piece0 on 192.168.0.243:35613 in memory (size: 4.2 KB, free: 366.3 MB)
17/04/28 21:09:37 INFO storage.BlockManagerInfo: Removed broadcast_13_piece0 on stack-0060.local:43606 in memory (size: 4.2 KB, free: 323.8 MB)
17/04/28 21:09:37 INFO storage.BlockManagerInfo: Removed broadcast_14_piece0 on 192.168.0.243:35613 in memory (size: 3.7 KB, free: 366.3 MB)
17/04/28 21:09:37 INFO storage.BlockManagerInfo: Removed broadcast_14_piece0 on stack-0060.local:43606 in memory (size: 3.7 KB, free: 323.8 MB)
17/04/28 21:09:37 WARN scheduler.TaskSetManager: Stage 10 contains a task of very large size (8900 KB). The maximum recommended task size is 100 KB.
17/04/28 21:09:37 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 10.0 (TID 16, stack-0060.local, executor 1, partition 0, PROCESS_LOCAL, 9113607 bytes)
17/04/28 21:09:37 INFO storage.BlockManagerInfo: Removed broadcast_15_piece0 on 192.168.0.243:35613 in memory (size: 22.6 KB, free: 366.3 MB)
17/04/28 21:09:37 INFO storage.BlockManagerInfo: Removed broadcast_15_piece0 on stack-0060.local:43606 in memory (size: 22.6 KB, free: 323.8 MB)
17/04/28 21:09:37 INFO spark.ContextCleaner: Cleaned accumulator 646
17/04/28 21:09:37 INFO storage.BlockManagerInfo: Added broadcast_16_piece0 in memory on stack-0060.local:43606 (size: 3.0 KB, free: 323.8 MB)
17/04/28 21:09:37 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 10.0 (TID 16) in 366 ms on stack-0060.local (executor 1) (1/1)
17/04/28 21:09:37 INFO cluster.YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool 
17/04/28 21:09:37 INFO scheduler.DAGScheduler: ShuffleMapStage 10 (parquet at Word2Vec.scala:314) finished in 0.238 s
17/04/28 21:09:37 INFO scheduler.DAGScheduler: looking for newly runnable stages
17/04/28 21:09:37 INFO scheduler.DAGScheduler: running: Set()
17/04/28 21:09:37 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 11)
17/04/28 21:09:37 INFO scheduler.DAGScheduler: failed: Set()
17/04/28 21:09:37 INFO scheduler.DAGScheduler: Submitting ResultStage 11 (ShuffledRowRDD[43] at parquet at Word2Vec.scala:314), which has no missing parents
17/04/28 21:09:37 INFO memory.MemoryStore: Block broadcast_17 stored as values in memory (estimated size 69.8 KB, free 366.0 MB)
17/04/28 21:09:37 INFO memory.MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 26.2 KB, free 365.9 MB)
17/04/28 21:09:37 INFO storage.BlockManagerInfo: Added broadcast_17_piece0 in memory on 192.168.0.243:35613 (size: 26.2 KB, free: 366.3 MB)
17/04/28 21:09:37 INFO spark.SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:996
17/04/28 21:09:37 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (ShuffledRowRDD[43] at parquet at Word2Vec.scala:314)
17/04/28 21:09:37 INFO cluster.YarnScheduler: Adding task set 11.0 with 1 tasks
17/04/28 21:09:37 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 11.0 (TID 17, stack-0060.local, executor 1, partition 0, NODE_LOCAL, 5904 bytes)
17/04/28 21:09:37 INFO storage.BlockManagerInfo: Added broadcast_17_piece0 in memory on stack-0060.local:43606 (size: 26.2 KB, free: 323.8 MB)
17/04/28 21:09:37 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 4 to 192.168.0.243:59816
17/04/28 21:09:37 INFO spark.MapOutputTrackerMaster: Size of output statuses for shuffle 4 is 147 bytes
17/04/28 21:09:40 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Disabling executor 1.
17/04/28 21:09:40 INFO scheduler.DAGScheduler: Executor lost: 1 (epoch 8)
17/04/28 21:09:40 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 1 from BlockManagerMaster.
17/04/28 21:09:40 INFO storage.BlockManagerMasterEndpoint: Removing block manager BlockManagerId(1, stack-0060.local, 43606, None)
17/04/28 21:09:40 INFO storage.BlockManagerMaster: Removed 1 successfully in removeExecutor
17/04/28 21:09:40 INFO scheduler.DAGScheduler: Shuffle files lost for executor: 1 (epoch 8)
17/04/28 21:09:40 INFO scheduler.ShuffleMapStage: ShuffleMapStage 10 is now unavailable on executor 1 (0/1, false)
17/04/28 21:09:41 ERROR cluster.YarnScheduler: Lost executor 1 on stack-0060.local: Container marked as failed: container_1493187723643_0017_01_000002 on host: stack-0060.local. Exit status: 1. Diagnostics: Exception from container-launch.
Container id: container_1493187723643_0017_01_000002
Exit code: 1
Stack trace: ExitCodeException exitCode=1: 
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:545)
	at org.apache.hadoop.util.Shell.run(Shell.java:456)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:722)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:211)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)


Container exited with a non-zero exit code 1

17/04/28 21:09:41 WARN scheduler.TaskSetManager: Lost task 0.0 in stage 11.0 (TID 17, stack-0060.local, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Container marked as failed: container_1493187723643_0017_01_000002 on host: stack-0060.local. Exit status: 1. Diagnostics: Exception from container-launch.
Container id: container_1493187723643_0017_01_000002
Exit code: 1
Stack trace: ExitCodeException exitCode=1: 
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:545)
	at org.apache.hadoop.util.Shell.run(Shell.java:456)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:722)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:211)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)


Container exited with a non-zero exit code 1

17/04/28 21:09:41 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Container marked as failed: container_1493187723643_0017_01_000002 on host: stack-0060.local. Exit status: 1. Diagnostics: Exception from container-launch.
Container id: container_1493187723643_0017_01_000002
Exit code: 1
Stack trace: ExitCodeException exitCode=1: 
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:545)
	at org.apache.hadoop.util.Shell.run(Shell.java:456)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:722)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:211)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)


Container exited with a non-zero exit code 1

17/04/28 21:09:41 INFO storage.BlockManagerMaster: Removal of executor 1 requested
17/04/28 21:09:41 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 1 from BlockManagerMaster.
17/04/28 21:09:41 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asked to remove non-existent executor 1
17/04/28 21:09:41 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Container marked as failed: container_1493187723643_0017_01_000006 on host: stack-0060.local. Exit status: 1. Diagnostics: Exception from container-launch.
Container id: container_1493187723643_0017_01_000006
Exit code: 1
Stack trace: ExitCodeException exitCode=1: 
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:545)
	at org.apache.hadoop.util.Shell.run(Shell.java:456)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:722)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:211)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)


Container exited with a non-zero exit code 1

17/04/28 21:09:41 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 4 from BlockManagerMaster.
17/04/28 21:09:41 INFO storage.BlockManagerMaster: Removal of executor 4 requested
17/04/28 21:09:41 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asked to remove non-existent executor 4
17/04/28 21:09:52 INFO cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(null)
17/04/28 21:09:52 INFO cluster.YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> stack-0060, PROXY_URI_BASES -> http://stack-0060:8088/proxy/application_1493187723643_0017), /proxy/application_1493187723643_0017
17/04/28 21:09:52 INFO ui.JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
17/04/28 21:09:57 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(null) (192.168.0.243:59856) with ID 4
17/04/28 21:09:57 INFO scheduler.TaskSetManager: Starting task 0.1 in stage 11.0 (TID 18, stack-0060.local, executor 4, partition 0, NODE_LOCAL, 5904 bytes)
17/04/28 21:09:57 INFO storage.BlockManagerMasterEndpoint: Registering block manager stack-0060.local:53857 with 366.3 MB RAM, BlockManagerId(4, stack-0060.local, 53857, None)
17/04/28 21:09:58 INFO storage.BlockManagerInfo: Added broadcast_17_piece0 in memory on stack-0060.local:53857 (size: 26.2 KB, free: 366.3 MB)
17/04/28 21:09:58 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 4 to 192.168.0.243:59856
17/04/28 21:09:58 INFO spark.MapOutputTrackerMaster: Size of output statuses for shuffle 4 is 85 bytes
17/04/28 21:09:58 WARN scheduler.TaskSetManager: Lost task 0.1 in stage 11.0 (TID 18, stack-0060.local, executor 4): FetchFailed(null, shuffleId=4, mapId=-1, reduceId=0, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 4
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:169)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

)
17/04/28 21:09:58 INFO scheduler.DAGScheduler: Marking ResultStage 11 (parquet at Word2Vec.scala:314) as failed due to a fetch failure from ShuffleMapStage 10 (parquet at Word2Vec.scala:314)
17/04/28 21:09:58 INFO scheduler.DAGScheduler: ResultStage 11 (parquet at Word2Vec.scala:314) failed in 20.946 s due to org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 4
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:169)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

17/04/28 21:09:58 INFO scheduler.DAGScheduler: Resubmitting ShuffleMapStage 10 (parquet at Word2Vec.scala:314) and ResultStage 11 (parquet at Word2Vec.scala:314) due to fetch failure
17/04/28 21:09:58 INFO scheduler.TaskSetManager: Task 0.1 in stage 11.0 (TID 18) failed, but another instance of the task has already succeeded, so not re-queuing the task to be re-executed.
17/04/28 21:09:58 INFO cluster.YarnScheduler: Removed TaskSet 11.0, whose tasks have all completed, from pool 
17/04/28 21:09:58 INFO scheduler.DAGScheduler: Resubmitting failed stages
17/04/28 21:09:58 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[42] at parquet at Word2Vec.scala:314), which has no missing parents
17/04/28 21:09:58 INFO memory.MemoryStore: Block broadcast_18 stored as values in memory (estimated size 5.0 KB, free 365.9 MB)
17/04/28 21:09:58 INFO memory.MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 3.0 KB, free 365.9 MB)
17/04/28 21:09:58 INFO storage.BlockManagerInfo: Added broadcast_18_piece0 in memory on 192.168.0.243:35613 (size: 3.0 KB, free: 366.2 MB)
17/04/28 21:09:58 INFO spark.SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:996
17/04/28 21:09:58 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[42] at parquet at Word2Vec.scala:314)
17/04/28 21:09:58 INFO cluster.YarnScheduler: Adding task set 10.1 with 1 tasks
17/04/28 21:09:58 WARN scheduler.TaskSetManager: Stage 10 contains a task of very large size (8900 KB). The maximum recommended task size is 100 KB.
17/04/28 21:09:58 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 10.1 (TID 19, stack-0060.local, executor 4, partition 0, PROCESS_LOCAL, 9113607 bytes)
17/04/28 21:09:59 INFO storage.BlockManagerInfo: Added broadcast_18_piece0 in memory on stack-0060.local:53857 (size: 3.0 KB, free: 366.3 MB)
17/04/28 21:09:59 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 10.1 (TID 19) in 516 ms on stack-0060.local (executor 4) (1/1)
17/04/28 21:09:59 INFO cluster.YarnScheduler: Removed TaskSet 10.1, whose tasks have all completed, from pool 
17/04/28 21:09:59 INFO scheduler.DAGScheduler: ShuffleMapStage 10 (parquet at Word2Vec.scala:314) finished in 0.517 s
17/04/28 21:09:59 INFO scheduler.DAGScheduler: looking for newly runnable stages
17/04/28 21:09:59 INFO scheduler.DAGScheduler: running: Set()
17/04/28 21:09:59 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 11)
17/04/28 21:09:59 INFO scheduler.DAGScheduler: failed: Set()
17/04/28 21:09:59 INFO scheduler.DAGScheduler: Submitting ResultStage 11 (ShuffledRowRDD[43] at parquet at Word2Vec.scala:314), which has no missing parents
17/04/28 21:09:59 INFO memory.MemoryStore: Block broadcast_19 stored as values in memory (estimated size 69.8 KB, free 365.9 MB)
17/04/28 21:09:59 INFO memory.MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 26.2 KB, free 365.8 MB)
17/04/28 21:09:59 INFO storage.BlockManagerInfo: Added broadcast_19_piece0 in memory on 192.168.0.243:35613 (size: 26.2 KB, free: 366.2 MB)
17/04/28 21:09:59 INFO spark.SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:996
17/04/28 21:09:59 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (ShuffledRowRDD[43] at parquet at Word2Vec.scala:314)
17/04/28 21:09:59 INFO cluster.YarnScheduler: Adding task set 11.1 with 1 tasks
17/04/28 21:09:59 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 11.1 (TID 20, stack-0060.local, executor 4, partition 0, NODE_LOCAL, 5904 bytes)
17/04/28 21:09:59 INFO storage.BlockManagerInfo: Added broadcast_19_piece0 in memory on stack-0060.local:53857 (size: 26.2 KB, free: 366.2 MB)
17/04/28 21:09:59 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 4 to 192.168.0.243:59856
17/04/28 21:09:59 INFO spark.MapOutputTrackerMaster: Size of output statuses for shuffle 4 is 147 bytes
17/04/28 21:10:00 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(null) (192.168.0.243:59859) with ID 5
17/04/28 21:10:00 INFO storage.BlockManagerInfo: Removed broadcast_16_piece0 on 192.168.0.243:35613 in memory (size: 3.0 KB, free: 366.2 MB)
17/04/28 21:10:00 INFO storage.BlockManagerInfo: Removed broadcast_17_piece0 on 192.168.0.243:35613 in memory (size: 26.2 KB, free: 366.3 MB)
17/04/28 21:10:00 INFO storage.BlockManagerInfo: Removed broadcast_17_piece0 on stack-0060.local:53857 in memory (size: 26.2 KB, free: 366.3 MB)
17/04/28 21:10:00 INFO storage.BlockManagerInfo: Removed broadcast_18_piece0 on 192.168.0.243:35613 in memory (size: 3.0 KB, free: 366.3 MB)
17/04/28 21:10:00 INFO storage.BlockManagerInfo: Removed broadcast_18_piece0 on stack-0060.local:53857 in memory (size: 3.0 KB, free: 366.3 MB)
17/04/28 21:10:00 INFO spark.ContextCleaner: Cleaned shuffle 1
17/04/28 21:10:00 INFO storage.BlockManager: Removing RDD 28
17/04/28 21:10:00 INFO spark.ContextCleaner: Cleaned RDD 28
17/04/28 21:10:00 INFO storage.BlockManagerMasterEndpoint: Registering block manager stack-0060.local:35980 with 366.3 MB RAM, BlockManagerId(5, stack-0060.local, 35980, None)
17/04/28 21:10:00 INFO spark.ContextCleaner: Cleaned accumulator 103
17/04/28 21:10:02 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 11.1 (TID 20) in 2794 ms on stack-0060.local (executor 4) (1/1)
17/04/28 21:10:02 INFO cluster.YarnScheduler: Removed TaskSet 11.1, whose tasks have all completed, from pool 
17/04/28 21:10:02 INFO scheduler.DAGScheduler: ResultStage 11 (parquet at Word2Vec.scala:314) finished in 2.793 s
17/04/28 21:10:02 INFO scheduler.DAGScheduler: Job 6 finished: parquet at Word2Vec.scala:314, took 24.940748 s
17/04/28 21:10:02 INFO datasources.FileFormatWriter: Job null committed.
17/04/28 21:10:03 WARN amfilter.AmIpFilter: Could not find proxy-user cookie, so user will not be set
17/04/28 21:10:03 WARN amfilter.AmIpFilter: Could not find proxy-user cookie, so user will not be set
create-word2vec-model.py
Got App ID. AppID = application_1493187723643_0017
17/04/28 21:10:03 WARN amfilter.AmIpFilter: Could not find proxy-user cookie, so user will not be set
17/04/28 21:10:03 WARN amfilter.AmIpFilter: Could not find proxy-user cookie, so user will not be set
17/04/28 21:10:03 WARN amfilter.AmIpFilter: Could not find proxy-user cookie, so user will not be set
17/04/28 21:10:03 WARN amfilter.AmIpFilter: Could not find proxy-user cookie, so user will not be set
17/04/28 21:10:03 WARN amfilter.AmIpFilter: Could not find proxy-user cookie, so user will not be set
17/04/28 21:10:03 WARN amfilter.AmIpFilter: Could not find proxy-user cookie, so user will not be set
17/04/28 21:10:03 INFO server.ServerConnector: Stopped ServerConnector@50f85a5f{HTTP/1.1}{0.0.0.0:4040}
17/04/28 21:10:03 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@2f78bbd{/stages/stage/kill,null,UNAVAILABLE}
17/04/28 21:10:03 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@72565928{/jobs/job/kill,null,UNAVAILABLE}
17/04/28 21:10:03 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@52079efa{/api,null,UNAVAILABLE}
17/04/28 21:10:03 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@2e4b4e64{/,null,UNAVAILABLE}
17/04/28 21:10:03 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@54ab1e31{/static,null,UNAVAILABLE}
17/04/28 21:10:03 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@5c495dc4{/executors/threadDump/json,null,UNAVAILABLE}
17/04/28 21:10:03 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@4be18ba{/executors/threadDump,null,UNAVAILABLE}
17/04/28 21:10:03 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@1d6b9fa5{/executors/json,null,UNAVAILABLE}
17/04/28 21:10:03 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@53885c6b{/executors,null,UNAVAILABLE}
17/04/28 21:10:03 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@3d01ab1{/environment/json,null,UNAVAILABLE}
17/04/28 21:10:03 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@39a12a0e{/environment,null,UNAVAILABLE}
17/04/28 21:10:03 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@1c76c583{/storage/rdd/json,null,UNAVAILABLE}
17/04/28 21:10:03 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@2a395ead{/storage/rdd,null,UNAVAILABLE}
17/04/28 21:10:03 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@d143748{/storage/json,null,UNAVAILABLE}
17/04/28 21:10:03 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@70d85e41{/storage,null,UNAVAILABLE}
17/04/28 21:10:03 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@72cca1{/stages/pool/json,null,UNAVAILABLE}
17/04/28 21:10:03 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@17fb7f8c{/stages/pool,null,UNAVAILABLE}
17/04/28 21:10:03 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@4894a95e{/stages/stage/json,null,UNAVAILABLE}
17/04/28 21:10:03 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@1aa1215a{/stages/stage,null,UNAVAILABLE}
17/04/28 21:10:03 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@15d61781{/stages/json,null,UNAVAILABLE}
17/04/28 21:10:03 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@11655d63{/stages,null,UNAVAILABLE}
17/04/28 21:10:03 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@70d488dc{/jobs/job/json,null,UNAVAILABLE}
17/04/28 21:10:03 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@7d324aea{/jobs/job,null,UNAVAILABLE}
17/04/28 21:10:03 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@64b842ee{/jobs/json,null,UNAVAILABLE}
17/04/28 21:10:03 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@326868cc{/jobs,null,UNAVAILABLE}
17/04/28 21:10:03 INFO ui.SparkUI: Stopped Spark web UI at http://192.168.0.243:4040
17/04/28 21:10:03 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread
17/04/28 21:10:04 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors
17/04/28 21:10:04 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down
17/04/28 21:10:04 INFO cluster.SchedulerExtensionServices: Stopping SchedulerExtensionServices
(serviceOption=None,
 services=List(),
 started=false)
17/04/28 21:10:04 INFO cluster.YarnClientSchedulerBackend: Stopped
17/04/28 21:10:04 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/04/28 21:10:04 INFO memory.MemoryStore: MemoryStore cleared
17/04/28 21:10:04 INFO storage.BlockManager: BlockManager stopped
17/04/28 21:10:04 INFO storage.BlockManagerMaster: BlockManagerMaster stopped
17/04/28 21:10:04 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/04/28 21:10:04 INFO spark.SparkContext: Successfully stopped SparkContext
17/04/28 21:10:04 INFO util.ShutdownHookManager: Shutdown hook called
17/04/28 21:10:04 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-1f2316cd-228c-4226-9115-22f427af0a07/pyspark-02155072-9079-45de-ad49-c2244b654d6d
17/04/28 21:10:04 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-1f2316cd-228c-4226-9115-22f427af0a07
