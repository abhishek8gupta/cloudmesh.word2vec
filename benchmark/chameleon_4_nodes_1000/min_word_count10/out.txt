17/04/28 19:42:00 INFO spark.SparkContext: Running Spark version 2.1.0
17/04/28 19:42:00 WARN spark.SparkContext: Support for Java 7 is deprecated as of Spark 2.0.0
17/04/28 19:42:02 INFO spark.SecurityManager: Changing view acls to: hadoop
17/04/28 19:42:02 INFO spark.SecurityManager: Changing modify acls to: hadoop
17/04/28 19:42:02 INFO spark.SecurityManager: Changing view acls groups to: 
17/04/28 19:42:02 INFO spark.SecurityManager: Changing modify acls groups to: 
17/04/28 19:42:02 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(hadoop); groups with view permissions: Set(); users  with modify permissions: Set(hadoop); groups with modify permissions: Set()
17/04/28 19:42:04 INFO util.Utils: Successfully started service 'sparkDriver' on port 46811.
17/04/28 19:42:04 INFO spark.SparkEnv: Registering MapOutputTracker
17/04/28 19:42:04 INFO spark.SparkEnv: Registering BlockManagerMaster
17/04/28 19:42:04 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/04/28 19:42:04 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/04/28 19:42:04 INFO storage.DiskBlockManager: Created local directory at /tmp/blockmgr-b9b3f459-8593-41ba-bd3e-867be4f6c48b
17/04/28 19:42:05 INFO memory.MemoryStore: MemoryStore started with capacity 366.3 MB
17/04/28 19:42:05 INFO spark.SparkEnv: Registering OutputCommitCoordinator
17/04/28 19:42:05 INFO util.log: Logging initialized @18109ms
17/04/28 19:42:06 INFO server.Server: jetty-9.2.z-SNAPSHOT
17/04/28 19:42:06 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@66019ed8{/jobs,null,AVAILABLE}
17/04/28 19:42:06 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7463ab39{/jobs/json,null,AVAILABLE}
17/04/28 19:42:06 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3b7e66e1{/jobs/job,null,AVAILABLE}
17/04/28 19:42:06 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@67945c4a{/jobs/job/json,null,AVAILABLE}
17/04/28 19:42:06 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3d373366{/stages,null,AVAILABLE}
17/04/28 19:42:06 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@730f8cef{/stages/json,null,AVAILABLE}
17/04/28 19:42:06 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1edd9ed{/stages/stage,null,AVAILABLE}
17/04/28 19:42:06 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@267e5798{/stages/stage/json,null,AVAILABLE}
17/04/28 19:42:06 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@30a8cfe6{/stages/pool,null,AVAILABLE}
17/04/28 19:42:06 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1ae91dff{/stages/pool/json,null,AVAILABLE}
17/04/28 19:42:06 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3eb05e26{/storage,null,AVAILABLE}
17/04/28 19:42:06 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2cf530f1{/storage/json,null,AVAILABLE}
17/04/28 19:42:06 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@15603546{/storage/rdd,null,AVAILABLE}
17/04/28 19:42:06 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5f4991a0{/storage/rdd/json,null,AVAILABLE}
17/04/28 19:42:06 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@56f7d03f{/environment,null,AVAILABLE}
17/04/28 19:42:06 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@278904b4{/environment/json,null,AVAILABLE}
17/04/28 19:42:06 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1493d9b3{/executors,null,AVAILABLE}
17/04/28 19:42:06 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@76b98152{/executors/json,null,AVAILABLE}
17/04/28 19:42:06 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@cd96b63{/executors/threadDump,null,AVAILABLE}
17/04/28 19:42:06 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1619372c{/executors/threadDump/json,null,AVAILABLE}
17/04/28 19:42:06 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@51753509{/static,null,AVAILABLE}
17/04/28 19:42:06 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@65ed0ba6{/,null,AVAILABLE}
17/04/28 19:42:06 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2d97f391{/api,null,AVAILABLE}
17/04/28 19:42:06 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@52f7cbf9{/jobs/job/kill,null,AVAILABLE}
17/04/28 19:42:06 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@a7072fd{/stages/stage/kill,null,AVAILABLE}
17/04/28 19:42:06 INFO server.ServerConnector: Started ServerConnector@30c6115f{HTTP/1.1}{0.0.0.0:4040}
17/04/28 19:42:06 INFO server.Server: Started @18601ms
17/04/28 19:42:06 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.
17/04/28 19:42:06 INFO ui.SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.0.243:4040
17/04/28 19:42:09 INFO client.RMProxy: Connecting to ResourceManager at stack-0060/192.168.0.243:8032
17/04/28 19:42:10 INFO yarn.Client: Requesting a new application from cluster with 1 NodeManagers
17/04/28 19:42:11 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (8192 MB per container)
17/04/28 19:42:11 INFO yarn.Client: Will allocate AM container, with 896 MB memory including 384 MB overhead
17/04/28 19:42:11 INFO yarn.Client: Setting up container launch context for our AM
17/04/28 19:42:11 INFO yarn.Client: Setting up the launch environment for our AM container
17/04/28 19:42:11 INFO yarn.Client: Preparing resources for our AM container
17/04/28 19:42:14 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
17/04/28 19:42:34 INFO yarn.Client: Uploading resource file:/tmp/spark-a14ff61a-ee4a-43c0-9753-2e5df4ddd78e/__spark_libs__4151264269751109827.zip -> hdfs://stack-0060/user/hadoop/.sparkStaging/application_1493187723643_0007/__spark_libs__4151264269751109827.zip
17/04/28 19:42:38 INFO yarn.Client: Uploading resource file:/opt/spark/python/lib/pyspark.zip -> hdfs://stack-0060/user/hadoop/.sparkStaging/application_1493187723643_0007/pyspark.zip
17/04/28 19:42:38 INFO yarn.Client: Uploading resource file:/opt/spark/python/lib/py4j-0.10.4-src.zip -> hdfs://stack-0060/user/hadoop/.sparkStaging/application_1493187723643_0007/py4j-0.10.4-src.zip
17/04/28 19:42:38 INFO yarn.Client: Uploading resource file:/tmp/spark-a14ff61a-ee4a-43c0-9753-2e5df4ddd78e/__spark_conf__1871125644890747447.zip -> hdfs://stack-0060/user/hadoop/.sparkStaging/application_1493187723643_0007/__spark_conf__.zip
17/04/28 19:42:38 INFO spark.SecurityManager: Changing view acls to: hadoop
17/04/28 19:42:38 INFO spark.SecurityManager: Changing modify acls to: hadoop
17/04/28 19:42:38 INFO spark.SecurityManager: Changing view acls groups to: 
17/04/28 19:42:38 INFO spark.SecurityManager: Changing modify acls groups to: 
17/04/28 19:42:38 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(hadoop); groups with view permissions: Set(); users  with modify permissions: Set(hadoop); groups with modify permissions: Set()
17/04/28 19:42:38 INFO yarn.Client: Submitting application application_1493187723643_0007 to ResourceManager
17/04/28 19:42:38 INFO impl.YarnClientImpl: Submitted application application_1493187723643_0007
17/04/28 19:42:38 INFO cluster.SchedulerExtensionServices: Starting Yarn extension services with app application_1493187723643_0007 and attemptId None
17/04/28 19:42:39 INFO yarn.Client: Application report for application_1493187723643_0007 (state: ACCEPTED)
17/04/28 19:42:39 INFO yarn.Client: 
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1493408558387
	 final status: UNDEFINED
	 tracking URL: http://stack-0060:8088/proxy/application_1493187723643_0007/
	 user: hadoop
17/04/28 19:42:40 INFO yarn.Client: Application report for application_1493187723643_0007 (state: ACCEPTED)
17/04/28 19:42:41 INFO yarn.Client: Application report for application_1493187723643_0007 (state: ACCEPTED)
17/04/28 19:42:42 INFO yarn.Client: Application report for application_1493187723643_0007 (state: ACCEPTED)
17/04/28 19:42:43 INFO yarn.Client: Application report for application_1493187723643_0007 (state: ACCEPTED)
17/04/28 19:42:43 INFO cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(null)
17/04/28 19:42:43 INFO cluster.YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> stack-0060, PROXY_URI_BASES -> http://stack-0060:8088/proxy/application_1493187723643_0007), /proxy/application_1493187723643_0007
17/04/28 19:42:43 INFO ui.JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
17/04/28 19:42:44 INFO yarn.Client: Application report for application_1493187723643_0007 (state: RUNNING)
17/04/28 19:42:44 INFO yarn.Client: 
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: 192.168.0.243
	 ApplicationMaster RPC port: 0
	 queue: default
	 start time: 1493408558387
	 final status: UNDEFINED
	 tracking URL: http://stack-0060:8088/proxy/application_1493187723643_0007/
	 user: hadoop
17/04/28 19:42:44 INFO cluster.YarnClientSchedulerBackend: Application application_1493187723643_0007 has started running.
17/04/28 19:42:44 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39783.
17/04/28 19:42:44 INFO netty.NettyBlockTransferService: Server created on 192.168.0.243:39783
17/04/28 19:42:44 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/04/28 19:42:44 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.0.243, 39783, None)
17/04/28 19:42:44 INFO storage.BlockManagerMasterEndpoint: Registering block manager 192.168.0.243:39783 with 366.3 MB RAM, BlockManagerId(driver, 192.168.0.243, 39783, None)
17/04/28 19:42:44 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.0.243, 39783, None)
17/04/28 19:42:44 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.0.243, 39783, None)
17/04/28 19:42:44 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4a3d08e4{/metrics/json,null,AVAILABLE}
17/04/28 19:42:44 INFO cluster.YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after waiting maxRegisteredResourcesWaitingTime: 30000(ms)
17/04/28 19:42:45 INFO internal.SharedState: Warehouse path is 'file:/opt/word2vec/data_process/spark-warehouse/'.
17/04/28 19:42:45 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@79bc158c{/SQL,null,AVAILABLE}
17/04/28 19:42:45 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@9fd4200{/SQL/json,null,AVAILABLE}
17/04/28 19:42:45 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@441bf055{/SQL/execution,null,AVAILABLE}
17/04/28 19:42:45 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@32c3fe22{/SQL/execution/json,null,AVAILABLE}
17/04/28 19:42:45 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5162ace8{/static/sql,null,AVAILABLE}
17/04/28 19:42:45 INFO memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 234.0 KB, free 366.1 MB)
17/04/28 19:42:46 INFO memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.5 KB, free 366.1 MB)
17/04/28 19:42:46 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.0.243:39783 (size: 20.5 KB, free: 366.3 MB)
17/04/28 19:42:46 INFO spark.SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:0
17/04/28 19:42:46 INFO mapred.FileInputFormat: Total input paths to process : 1
17/04/28 19:42:46 INFO spark.SparkContext: Starting job: runJob at PythonRDD.scala:441
17/04/28 19:42:46 INFO scheduler.DAGScheduler: Got job 0 (runJob at PythonRDD.scala:441) with 1 output partitions
17/04/28 19:42:46 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (runJob at PythonRDD.scala:441)
17/04/28 19:42:46 INFO scheduler.DAGScheduler: Parents of final stage: List()
17/04/28 19:42:46 INFO scheduler.DAGScheduler: Missing parents: List()
17/04/28 19:42:46 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (PythonRDD[3] at RDD at PythonRDD.scala:48), which has no missing parents
17/04/28 19:42:46 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 7.0 KB, free 366.0 MB)
17/04/28 19:42:46 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.2 KB, free 366.0 MB)
17/04/28 19:42:46 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.0.243:39783 (size: 4.2 KB, free: 366.3 MB)
17/04/28 19:42:46 INFO spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:996
17/04/28 19:42:46 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (PythonRDD[3] at RDD at PythonRDD.scala:48)
17/04/28 19:42:46 INFO cluster.YarnScheduler: Adding task set 0.0 with 1 tasks
17/04/28 19:42:48 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(null) (192.168.0.243:46962) with ID 1
17/04/28 19:42:48 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, stack-0060.local, executor 1, partition 0, NODE_LOCAL, 5938 bytes)
17/04/28 19:42:48 INFO storage.BlockManagerMasterEndpoint: Registering block manager stack-0060.local:48293 with 366.3 MB RAM, BlockManagerId(1, stack-0060.local, 48293, None)
17/04/28 19:42:48 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on stack-0060.local:48293 (size: 4.2 KB, free: 366.3 MB)
17/04/28 19:42:49 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on stack-0060.local:48293 (size: 20.5 KB, free: 366.3 MB)
17/04/28 19:42:49 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(null) (192.168.0.243:46964) with ID 2
17/04/28 19:42:49 INFO storage.BlockManagerMasterEndpoint: Registering block manager stack-0060.local:49068 with 366.3 MB RAM, BlockManagerId(2, stack-0060.local, 49068, None)
17/04/28 19:42:51 INFO storage.BlockManagerInfo: Added rdd_2_0 in memory on stack-0060.local:48293 (size: 3.7 MB, free: 362.5 MB)
17/04/28 19:42:51 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 2712 ms on stack-0060.local (executor 1) (1/1)
17/04/28 19:42:51 INFO cluster.YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/04/28 19:42:51 INFO scheduler.DAGScheduler: ResultStage 0 (runJob at PythonRDD.scala:441) finished in 4.903 s
17/04/28 19:42:51 INFO scheduler.DAGScheduler: Job 0 finished: runJob at PythonRDD.scala:441, took 5.155604 s
17/04/28 19:42:51 INFO storage.BlockManagerInfo: Removed broadcast_1_piece0 on 192.168.0.243:39783 in memory (size: 4.2 KB, free: 366.3 MB)
17/04/28 19:42:51 INFO storage.BlockManagerInfo: Removed broadcast_1_piece0 on stack-0060.local:48293 in memory (size: 4.2 KB, free: 362.5 MB)
17/04/28 19:42:53 INFO codegen.CodeGenerator: Code generated in 364.412229 ms
=========tokDF============
17/04/28 19:42:53 INFO spark.SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
17/04/28 19:42:53 INFO scheduler.DAGScheduler: Got job 1 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/04/28 19:42:53 INFO scheduler.DAGScheduler: Final stage: ResultStage 1 (showString at NativeMethodAccessorImpl.java:0)
17/04/28 19:42:53 INFO scheduler.DAGScheduler: Parents of final stage: List()
17/04/28 19:42:53 INFO scheduler.DAGScheduler: Missing parents: List()
17/04/28 19:42:53 INFO scheduler.DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[14] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
17/04/28 19:42:53 INFO memory.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 23.9 KB, free 366.0 MB)
17/04/28 19:42:53 INFO memory.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 11.9 KB, free 366.0 MB)
17/04/28 19:42:53 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.0.243:39783 (size: 11.9 KB, free: 366.3 MB)
17/04/28 19:42:53 INFO spark.SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:996
17/04/28 19:42:53 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[14] at showString at NativeMethodAccessorImpl.java:0)
17/04/28 19:42:53 INFO cluster.YarnScheduler: Adding task set 1.0 with 1 tasks
17/04/28 19:42:53 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, stack-0060.local, executor 1, partition 0, PROCESS_LOCAL, 5967 bytes)
17/04/28 19:42:53 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on stack-0060.local:48293 (size: 11.9 KB, free: 362.5 MB)
17/04/28 19:42:55 INFO storage.BlockManagerInfo: Added rdd_9_0 in memory on stack-0060.local:48293 (size: 3.6 MB, free: 358.9 MB)
17/04/28 19:42:57 INFO storage.BlockManagerInfo: Added rdd_12_0 in memory on stack-0060.local:48293 (size: 13.9 MB, free: 345.0 MB)
17/04/28 19:42:57 INFO scheduler.DAGScheduler: ResultStage 1 (showString at NativeMethodAccessorImpl.java:0) finished in 3.987 s
17/04/28 19:42:57 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 3984 ms on stack-0060.local (executor 1) (1/1)
17/04/28 19:42:57 INFO scheduler.DAGScheduler: Job 1 finished: showString at NativeMethodAccessorImpl.java:0, took 4.027107 s
17/04/28 19:42:57 INFO cluster.YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/04/28 19:42:57 INFO codegen.CodeGenerator: Code generated in 35.752237 ms
+--------------------+--------------------+
|                text|               words|
+--------------------+--------------------+
|Andre Dwayne Russ...|[andre, dwayne, r...|
|                    |                  []|
|                    |                  []|
|   Style of Batti...|[, , , style, of,...|
|Russell has a uni...|[russell, has, a,...|
|                    |                  []|
|                    |                  []|
|   Domestic caree...|[, , , domestic, ...|
|In the season 201...|[in, the, season,...|
|                    |                  []|
|                    |                  []|
|   International ...|[, , , internatio...|
|A fast bowling al...|[a, fast, bowling...|
|He made his ODI d...|[he, made, his, o...|
|After a poor home...|[after, a, poor, ...|
|                    |                  []|
|                    |                  []|
|   Indian Premier...|[, , , indian, pr...|
|During the 2012 I...|[during, the, 201...|
|On 21 September 2...|[on, 21, septembe...|
+--------------------+--------------------+
only showing top 20 rows

17/04/28 19:42:57 INFO spark.SparkContext: Starting job: collect at Word2Vec.scala:195
17/04/28 19:42:57 INFO scheduler.DAGScheduler: Registering RDD 20 (map at Word2Vec.scala:186)
17/04/28 19:42:57 INFO scheduler.DAGScheduler: Got job 2 (collect at Word2Vec.scala:195) with 2 output partitions
17/04/28 19:42:57 INFO scheduler.DAGScheduler: Final stage: ResultStage 3 (collect at Word2Vec.scala:195)
17/04/28 19:42:57 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
17/04/28 19:42:57 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 2)
17/04/28 19:42:57 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[20] at map at Word2Vec.scala:186), which has no missing parents
17/04/28 19:42:57 INFO memory.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 27.5 KB, free 366.0 MB)
17/04/28 19:42:57 INFO memory.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 13.6 KB, free 366.0 MB)
17/04/28 19:42:57 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 192.168.0.243:39783 (size: 13.6 KB, free: 366.3 MB)
17/04/28 19:42:57 INFO spark.SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:996
17/04/28 19:42:57 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[20] at map at Word2Vec.scala:186)
17/04/28 19:42:57 INFO cluster.YarnScheduler: Adding task set 2.0 with 2 tasks
17/04/28 19:42:57 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, stack-0060.local, executor 1, partition 0, PROCESS_LOCAL, 6012 bytes)
17/04/28 19:42:57 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 2.0 (TID 3, stack-0060.local, executor 2, partition 1, NODE_LOCAL, 6012 bytes)
17/04/28 19:42:57 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on stack-0060.local:48293 (size: 13.6 KB, free: 345.0 MB)
17/04/28 19:42:58 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on stack-0060.local:49068 (size: 13.6 KB, free: 366.3 MB)
17/04/28 19:42:58 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on stack-0060.local:49068 (size: 20.5 KB, free: 366.3 MB)
17/04/28 19:43:00 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 2278 ms on stack-0060.local (executor 1) (1/2)
17/04/28 19:43:01 INFO storage.BlockManagerInfo: Added rdd_2_1 in memory on stack-0060.local:49068 (size: 3.7 MB, free: 362.5 MB)
17/04/28 19:43:03 INFO storage.BlockManagerInfo: Added rdd_9_1 in memory on stack-0060.local:49068 (size: 3.6 MB, free: 358.9 MB)
17/04/28 19:43:08 INFO storage.BlockManagerInfo: Added rdd_12_1 in memory on stack-0060.local:49068 (size: 13.9 MB, free: 345.1 MB)
17/04/28 19:43:09 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 2.0 (TID 3) in 12106 ms on stack-0060.local (executor 2) (2/2)
17/04/28 19:43:09 INFO cluster.YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/04/28 19:43:09 INFO scheduler.DAGScheduler: ShuffleMapStage 2 (map at Word2Vec.scala:186) finished in 12.113 s
17/04/28 19:43:09 INFO scheduler.DAGScheduler: looking for newly runnable stages
17/04/28 19:43:09 INFO scheduler.DAGScheduler: running: Set()
17/04/28 19:43:09 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 3)
17/04/28 19:43:09 INFO scheduler.DAGScheduler: failed: Set()
17/04/28 19:43:10 INFO scheduler.DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[23] at map at Word2Vec.scala:189), which has no missing parents
17/04/28 19:43:10 INFO memory.MemoryStore: Block broadcast_4 stored as values in memory (estimated size 4.8 KB, free 366.0 MB)
17/04/28 19:43:10 INFO memory.MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.6 KB, free 366.0 MB)
17/04/28 19:43:10 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on 192.168.0.243:39783 (size: 2.6 KB, free: 366.3 MB)
17/04/28 19:43:10 INFO spark.SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:996
17/04/28 19:43:10 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from ResultStage 3 (MapPartitionsRDD[23] at map at Word2Vec.scala:189)
17/04/28 19:43:10 INFO cluster.YarnScheduler: Adding task set 3.0 with 2 tasks
17/04/28 19:43:10 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 3.0 (TID 4, stack-0060.local, executor 1, partition 0, NODE_LOCAL, 5762 bytes)
17/04/28 19:43:10 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 3.0 (TID 5, stack-0060.local, executor 2, partition 1, NODE_LOCAL, 5762 bytes)
17/04/28 19:43:10 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on stack-0060.local:48293 (size: 2.6 KB, free: 345.0 MB)
17/04/28 19:43:10 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on stack-0060.local:49068 (size: 2.6 KB, free: 345.1 MB)
17/04/28 19:43:10 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 192.168.0.243:46962
17/04/28 19:43:10 INFO spark.MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 166 bytes
17/04/28 19:43:10 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 192.168.0.243:46964
17/04/28 19:43:10 INFO spark.ContextCleaner: Cleaned accumulator 54
17/04/28 19:43:10 INFO storage.BlockManagerInfo: Removed broadcast_2_piece0 on 192.168.0.243:39783 in memory (size: 11.9 KB, free: 366.3 MB)
17/04/28 19:43:10 INFO storage.BlockManagerInfo: Removed broadcast_2_piece0 on stack-0060.local:48293 in memory (size: 11.9 KB, free: 345.0 MB)
17/04/28 19:43:10 INFO storage.BlockManagerInfo: Removed broadcast_3_piece0 on 192.168.0.243:39783 in memory (size: 13.6 KB, free: 366.3 MB)
17/04/28 19:43:10 INFO storage.BlockManagerInfo: Removed broadcast_3_piece0 on stack-0060.local:48293 in memory (size: 13.6 KB, free: 345.0 MB)
17/04/28 19:43:11 INFO storage.BlockManagerInfo: Removed broadcast_3_piece0 on stack-0060.local:49068 in memory (size: 13.6 KB, free: 345.1 MB)
17/04/28 19:43:11 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Disabling executor 2.
17/04/28 19:43:11 INFO scheduler.DAGScheduler: Executor lost: 2 (epoch 1)
17/04/28 19:43:11 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 2 from BlockManagerMaster.
17/04/28 19:43:11 INFO storage.BlockManagerMasterEndpoint: Removing block manager BlockManagerId(2, stack-0060.local, 49068, None)
17/04/28 19:43:11 INFO storage.BlockManagerMaster: Removed 2 successfully in removeExecutor
17/04/28 19:43:11 INFO scheduler.DAGScheduler: Shuffle files lost for executor: 2 (epoch 1)
17/04/28 19:43:11 INFO scheduler.ShuffleMapStage: ShuffleMapStage 2 is now unavailable on executor 2 (1/2, false)
17/04/28 19:43:11 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Container marked as failed: container_1493187723643_0007_01_000003 on host: stack-0060.local. Exit status: 1. Diagnostics: Exception from container-launch.
Container id: container_1493187723643_0007_01_000003
Exit code: 1
Stack trace: ExitCodeException exitCode=1: 
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:545)
	at org.apache.hadoop.util.Shell.run(Shell.java:456)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:722)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:211)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)


Container exited with a non-zero exit code 1

17/04/28 19:43:11 ERROR cluster.YarnScheduler: Lost executor 2 on stack-0060.local: Container marked as failed: container_1493187723643_0007_01_000003 on host: stack-0060.local. Exit status: 1. Diagnostics: Exception from container-launch.
Container id: container_1493187723643_0007_01_000003
Exit code: 1
Stack trace: ExitCodeException exitCode=1: 
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:545)
	at org.apache.hadoop.util.Shell.run(Shell.java:456)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:722)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:211)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)


Container exited with a non-zero exit code 1

17/04/28 19:43:11 WARN scheduler.TaskSetManager: Lost task 1.0 in stage 3.0 (TID 5, stack-0060.local, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container marked as failed: container_1493187723643_0007_01_000003 on host: stack-0060.local. Exit status: 1. Diagnostics: Exception from container-launch.
Container id: container_1493187723643_0007_01_000003
Exit code: 1
Stack trace: ExitCodeException exitCode=1: 
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:545)
	at org.apache.hadoop.util.Shell.run(Shell.java:456)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:722)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:211)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)


Container exited with a non-zero exit code 1

17/04/28 19:43:11 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 2 from BlockManagerMaster.
17/04/28 19:43:11 INFO storage.BlockManagerMaster: Removal of executor 2 requested
17/04/28 19:43:11 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asked to remove non-existent executor 2
17/04/28 19:43:11 INFO storage.BlockManagerInfo: Added taskresult_4 in memory on stack-0060.local:48293 (size: 2.3 MB, free: 342.7 MB)
17/04/28 19:43:11 INFO scheduler.TaskSetManager: Starting task 1.1 in stage 3.0 (TID 6, stack-0060.local, executor 1, partition 1, NODE_LOCAL, 5762 bytes)
17/04/28 19:43:11 INFO client.TransportClientFactory: Successfully created connection to stack-0060.local/192.168.0.243:48293 after 9 ms (0 ms spent in bootstraps)
17/04/28 19:43:12 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 3.0 (TID 4) in 2017 ms on stack-0060.local (executor 1) (1/2)
17/04/28 19:43:12 INFO storage.BlockManagerInfo: Removed taskresult_4 on stack-0060.local:48293 in memory (size: 2.3 MB, free: 345.0 MB)
17/04/28 19:43:20 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(null) (192.168.0.243:46984) with ID 3
17/04/28 19:43:20 INFO storage.BlockManagerMasterEndpoint: Registering block manager stack-0060.local:37269 with 366.3 MB RAM, BlockManagerId(3, stack-0060.local, 37269, None)
17/04/28 19:43:26 WARN scheduler.TaskSetManager: Lost task 1.1 in stage 3.0 (TID 6, stack-0060.local, executor 1): FetchFailed(BlockManagerId(2, stack-0060.local, 49068, None), shuffleId=0, mapId=1, reduceId=1, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to stack-0060.local/192.168.0.243:49068
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:357)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:332)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:54)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:85)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:109)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: Failed to connect to stack-0060.local/192.168.0.243:49068
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:228)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:179)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:140)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.access$200(RetryingBlockFetcher.java:43)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher$1.run(RetryingBlockFetcher.java:170)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: stack-0060.local/192.168.0.243:49068
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:640)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:575)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:489)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:451)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:140)
	... 2 more

)
17/04/28 19:43:26 INFO scheduler.TaskSetManager: Task 1.1 in stage 3.0 (TID 6) failed, but another instance of the task has already succeeded, so not re-queuing the task to be re-executed.
17/04/28 19:43:26 INFO scheduler.DAGScheduler: Marking ResultStage 3 (collect at Word2Vec.scala:195) as failed due to a fetch failure from ShuffleMapStage 2 (map at Word2Vec.scala:186)
17/04/28 19:43:26 INFO cluster.YarnScheduler: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/04/28 19:43:26 INFO scheduler.DAGScheduler: ResultStage 3 (collect at Word2Vec.scala:195) failed in 16.831 s due to org.apache.spark.shuffle.FetchFailedException: Failed to connect to stack-0060.local/192.168.0.243:49068
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:357)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:332)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:54)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:85)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:109)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: Failed to connect to stack-0060.local/192.168.0.243:49068
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:228)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:179)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:140)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.access$200(RetryingBlockFetcher.java:43)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher$1.run(RetryingBlockFetcher.java:170)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: stack-0060.local/192.168.0.243:49068
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:640)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:575)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:489)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:451)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:140)
	... 2 more

17/04/28 19:43:26 INFO scheduler.DAGScheduler: Resubmitting ShuffleMapStage 2 (map at Word2Vec.scala:186) and ResultStage 3 (collect at Word2Vec.scala:195) due to fetch failure
17/04/28 19:43:27 INFO scheduler.DAGScheduler: Resubmitting failed stages
17/04/28 19:43:27 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[20] at map at Word2Vec.scala:186), which has no missing parents
17/04/28 19:43:27 INFO memory.MemoryStore: Block broadcast_5 stored as values in memory (estimated size 27.5 KB, free 366.0 MB)
17/04/28 19:43:27 INFO memory.MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 13.6 KB, free 366.0 MB)
17/04/28 19:43:27 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on 192.168.0.243:39783 (size: 13.6 KB, free: 366.3 MB)
17/04/28 19:43:27 INFO spark.SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:996
17/04/28 19:43:27 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[20] at map at Word2Vec.scala:186)
17/04/28 19:43:27 INFO cluster.YarnScheduler: Adding task set 2.1 with 1 tasks
17/04/28 19:43:27 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 2.1 (TID 7, stack-0060.local, executor 1, partition 1, NODE_LOCAL, 6012 bytes)
17/04/28 19:43:27 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on stack-0060.local:48293 (size: 13.6 KB, free: 345.0 MB)
17/04/28 19:43:27 INFO storage.BlockManagerInfo: Added rdd_2_1 in memory on stack-0060.local:48293 (size: 3.7 MB, free: 341.2 MB)
17/04/28 19:43:28 INFO storage.BlockManagerInfo: Added rdd_9_1 in memory on stack-0060.local:48293 (size: 3.6 MB, free: 337.6 MB)
17/04/28 19:43:28 INFO storage.BlockManagerInfo: Added rdd_12_1 in memory on stack-0060.local:48293 (size: 13.9 MB, free: 323.8 MB)
17/04/28 19:43:29 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 2.1 (TID 7) in 2337 ms on stack-0060.local (executor 1) (1/1)
17/04/28 19:43:29 INFO cluster.YarnScheduler: Removed TaskSet 2.1, whose tasks have all completed, from pool 
17/04/28 19:43:29 INFO scheduler.DAGScheduler: ShuffleMapStage 2 (map at Word2Vec.scala:186) finished in 2.341 s
17/04/28 19:43:29 INFO scheduler.DAGScheduler: looking for newly runnable stages
17/04/28 19:43:29 INFO scheduler.DAGScheduler: running: Set()
17/04/28 19:43:29 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 3)
17/04/28 19:43:29 INFO scheduler.DAGScheduler: failed: Set()
17/04/28 19:43:29 INFO scheduler.DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[23] at map at Word2Vec.scala:189), which has no missing parents
17/04/28 19:43:29 INFO memory.MemoryStore: Block broadcast_6 stored as values in memory (estimated size 4.8 KB, free 366.0 MB)
17/04/28 19:43:29 INFO memory.MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.6 KB, free 366.0 MB)
17/04/28 19:43:29 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on 192.168.0.243:39783 (size: 2.6 KB, free: 366.3 MB)
17/04/28 19:43:29 INFO spark.SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:996
17/04/28 19:43:29 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[23] at map at Word2Vec.scala:189)
17/04/28 19:43:29 INFO cluster.YarnScheduler: Adding task set 3.1 with 1 tasks
17/04/28 19:43:29 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 3.1 (TID 8, stack-0060.local, executor 1, partition 1, NODE_LOCAL, 5762 bytes)
17/04/28 19:43:29 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on stack-0060.local:48293 (size: 2.6 KB, free: 323.8 MB)
17/04/28 19:43:29 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 192.168.0.243:46962
17/04/28 19:43:29 INFO spark.MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 159 bytes
17/04/28 19:43:29 INFO storage.BlockManagerInfo: Added taskresult_8 in memory on stack-0060.local:48293 (size: 2.3 MB, free: 321.5 MB)
17/04/28 19:43:29 INFO storage.BlockManagerInfo: Removed taskresult_8 on stack-0060.local:48293 in memory (size: 2.3 MB, free: 323.8 MB)
17/04/28 19:43:29 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 3.1 (TID 8) in 392 ms on stack-0060.local (executor 1) (1/1)
17/04/28 19:43:29 INFO cluster.YarnScheduler: Removed TaskSet 3.1, whose tasks have all completed, from pool 
17/04/28 19:43:29 INFO scheduler.DAGScheduler: ResultStage 3 (collect at Word2Vec.scala:195) finished in 0.391 s
17/04/28 19:43:29 INFO scheduler.DAGScheduler: Job 2 finished: collect at Word2Vec.scala:195, took 32.232046 s
17/04/28 19:43:29 INFO feature.Word2Vec: vocabSize = 12983, trainWordsCount = 2197453
17/04/28 19:43:29 INFO memory.MemoryStore: Block broadcast_7 stored as values in memory (estimated size 3.9 KB, free 366.0 MB)
17/04/28 19:43:29 INFO memory.MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 4.0 KB, free 366.0 MB)
17/04/28 19:43:29 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on 192.168.0.243:39783 (size: 4.0 KB, free: 366.3 MB)
17/04/28 19:43:29 INFO spark.SparkContext: Created broadcast 7 from broadcast at Word2Vec.scala:314
17/04/28 19:43:30 INFO memory.MemoryStore: Block broadcast_8 stored as values in memory (estimated size 5.5 MB, free 360.5 MB)
17/04/28 19:43:30 INFO memory.MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 520.4 KB, free 360.0 MB)
17/04/28 19:43:30 INFO storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on 192.168.0.243:39783 (size: 520.4 KB, free: 365.7 MB)
17/04/28 19:43:30 INFO spark.SparkContext: Created broadcast 8 from broadcast at Word2Vec.scala:315
17/04/28 19:43:30 INFO memory.MemoryStore: Block broadcast_9 stored as values in memory (estimated size 1097.1 KB, free 358.9 MB)
17/04/28 19:43:30 INFO memory.MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 145.7 KB, free 358.8 MB)
17/04/28 19:43:30 INFO storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on 192.168.0.243:39783 (size: 145.7 KB, free: 365.6 MB)
17/04/28 19:43:30 INFO spark.SparkContext: Created broadcast 9 from broadcast at Word2Vec.scala:316
17/04/28 19:43:30 INFO storage.BlockManagerInfo: Removed broadcast_6_piece0 on 192.168.0.243:39783 in memory (size: 2.6 KB, free: 365.6 MB)
17/04/28 19:43:30 INFO storage.BlockManagerInfo: Removed broadcast_6_piece0 on stack-0060.local:48293 in memory (size: 2.6 KB, free: 323.8 MB)
17/04/28 19:43:30 INFO storage.BlockManagerInfo: Removed broadcast_5_piece0 on 192.168.0.243:39783 in memory (size: 13.6 KB, free: 365.6 MB)
17/04/28 19:43:30 INFO storage.BlockManagerInfo: Removed broadcast_5_piece0 on stack-0060.local:48293 in memory (size: 13.6 KB, free: 323.8 MB)
17/04/28 19:43:30 INFO storage.BlockManagerInfo: Removed broadcast_4_piece0 on 192.168.0.243:39783 in memory (size: 2.6 KB, free: 365.6 MB)
17/04/28 19:43:30 INFO storage.BlockManagerInfo: Removed broadcast_4_piece0 on stack-0060.local:48293 in memory (size: 2.6 KB, free: 323.8 MB)
17/04/28 19:43:30 INFO spark.ContextCleaner: Cleaned shuffle 0
17/04/28 19:43:30 INFO memory.MemoryStore: Block broadcast_10 stored as values in memory (estimated size 5.0 MB, free 353.9 MB)
17/04/28 19:43:30 INFO memory.MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 4.0 MB, free 349.9 MB)
17/04/28 19:43:30 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on 192.168.0.243:39783 (size: 4.0 MB, free: 361.6 MB)
17/04/28 19:43:30 INFO memory.MemoryStore: Block broadcast_10_piece1 stored as bytes in memory (estimated size 978.8 KB, free 348.9 MB)
17/04/28 19:43:30 INFO storage.BlockManagerInfo: Added broadcast_10_piece1 in memory on 192.168.0.243:39783 (size: 978.8 KB, free: 360.7 MB)
17/04/28 19:43:30 INFO spark.SparkContext: Created broadcast 10 from broadcast at Word2Vec.scala:344
17/04/28 19:43:30 INFO memory.MemoryStore: Block broadcast_11 stored as values in memory (estimated size 5.0 MB, free 344.0 MB)
17/04/28 19:43:30 INFO memory.MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 24.8 KB, free 344.0 MB)
17/04/28 19:43:30 INFO storage.BlockManagerInfo: Added broadcast_11_piece0 in memory on 192.168.0.243:39783 (size: 24.8 KB, free: 360.6 MB)
17/04/28 19:43:30 INFO spark.SparkContext: Created broadcast 11 from broadcast at Word2Vec.scala:345
17/04/28 19:43:30 INFO spark.SparkContext: Starting job: collect at Word2Vec.scala:423
17/04/28 19:43:30 INFO scheduler.DAGScheduler: Registering RDD 25 (repartition at Word2Vec.scala:329)
17/04/28 19:43:30 INFO scheduler.DAGScheduler: Registering RDD 29 (mapPartitionsWithIndex at Word2Vec.scala:346)
17/04/28 19:43:30 INFO scheduler.DAGScheduler: Got job 3 (collect at Word2Vec.scala:423) with 1 output partitions
17/04/28 19:43:30 INFO scheduler.DAGScheduler: Final stage: ResultStage 6 (collect at Word2Vec.scala:423)
17/04/28 19:43:30 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
17/04/28 19:43:30 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 5)
17/04/28 19:43:30 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[25] at repartition at Word2Vec.scala:329), which has no missing parents
17/04/28 19:43:30 INFO memory.MemoryStore: Block broadcast_12 stored as values in memory (estimated size 28.3 KB, free 343.9 MB)
17/04/28 19:43:30 INFO memory.MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 13.9 KB, free 343.9 MB)
17/04/28 19:43:30 INFO storage.BlockManagerInfo: Added broadcast_12_piece0 in memory on 192.168.0.243:39783 (size: 13.9 KB, free: 360.6 MB)
17/04/28 19:43:30 INFO spark.SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:996
17/04/28 19:43:30 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[25] at repartition at Word2Vec.scala:329)
17/04/28 19:43:30 INFO cluster.YarnScheduler: Adding task set 4.0 with 2 tasks
17/04/28 19:43:30 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 4.0 (TID 9, stack-0060.local, executor 1, partition 0, PROCESS_LOCAL, 6012 bytes)
17/04/28 19:43:30 INFO storage.BlockManagerInfo: Added broadcast_12_piece0 in memory on stack-0060.local:48293 (size: 13.9 KB, free: 323.8 MB)
17/04/28 19:43:30 INFO storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on stack-0060.local:48293 (size: 145.7 KB, free: 323.6 MB)
17/04/28 19:43:32 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 4.0 (TID 10, stack-0060.local, executor 1, partition 1, PROCESS_LOCAL, 6012 bytes)
17/04/28 19:43:32 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 4.0 (TID 9) in 1310 ms on stack-0060.local (executor 1) (1/2)
17/04/28 19:43:32 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 4.0 (TID 10) in 635 ms on stack-0060.local (executor 1) (2/2)
17/04/28 19:43:32 INFO cluster.YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool 
17/04/28 19:43:32 INFO scheduler.DAGScheduler: ShuffleMapStage 4 (repartition at Word2Vec.scala:329) finished in 1.948 s
17/04/28 19:43:32 INFO scheduler.DAGScheduler: looking for newly runnable stages
17/04/28 19:43:32 INFO scheduler.DAGScheduler: running: Set()
17/04/28 19:43:32 INFO scheduler.DAGScheduler: waiting: Set(ShuffleMapStage 5, ResultStage 6)
17/04/28 19:43:32 INFO scheduler.DAGScheduler: failed: Set()
17/04/28 19:43:32 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[29] at mapPartitionsWithIndex at Word2Vec.scala:346), which has no missing parents
17/04/28 19:43:32 INFO memory.MemoryStore: Block broadcast_13 stored as values in memory (estimated size 6.3 KB, free 343.9 MB)
17/04/28 19:43:32 INFO memory.MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 3.4 KB, free 343.9 MB)
17/04/28 19:43:32 INFO storage.BlockManagerInfo: Added broadcast_13_piece0 in memory on 192.168.0.243:39783 (size: 3.4 KB, free: 360.6 MB)
17/04/28 19:43:32 INFO spark.SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:996
17/04/28 19:43:32 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[29] at mapPartitionsWithIndex at Word2Vec.scala:346)
17/04/28 19:43:32 INFO cluster.YarnScheduler: Adding task set 5.0 with 1 tasks
17/04/28 19:43:32 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 5.0 (TID 11, stack-0060.local, executor 3, partition 0, NODE_LOCAL, 6027 bytes)
17/04/28 19:43:33 INFO storage.BlockManagerInfo: Added broadcast_13_piece0 in memory on stack-0060.local:37269 (size: 3.4 KB, free: 366.3 MB)
17/04/28 19:43:33 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 192.168.0.243:46984
17/04/28 19:43:33 INFO spark.MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 156 bytes
17/04/28 19:43:34 INFO storage.BlockManagerInfo: Added rdd_28_0 in memory on stack-0060.local:37269 (size: 9.5 MB, free: 356.8 MB)
17/04/28 19:43:34 INFO storage.BlockManagerInfo: Added broadcast_10_piece1 in memory on stack-0060.local:37269 (size: 978.8 KB, free: 355.9 MB)
17/04/28 19:43:34 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on stack-0060.local:37269 (size: 4.0 MB, free: 351.9 MB)
17/04/28 19:43:34 INFO storage.BlockManagerInfo: Added broadcast_11_piece0 in memory on stack-0060.local:37269 (size: 24.8 KB, free: 351.8 MB)
17/04/28 19:43:34 INFO storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on stack-0060.local:37269 (size: 520.4 KB, free: 351.3 MB)
17/04/28 19:43:34 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on stack-0060.local:37269 (size: 4.0 KB, free: 351.3 MB)
17/04/28 19:43:39 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Disabling executor 3.
17/04/28 19:43:39 INFO scheduler.DAGScheduler: Executor lost: 3 (epoch 5)
17/04/28 19:43:39 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 3 from BlockManagerMaster.
17/04/28 19:43:39 INFO storage.BlockManagerMasterEndpoint: Removing block manager BlockManagerId(3, stack-0060.local, 37269, None)
17/04/28 19:43:39 INFO storage.BlockManagerMaster: Removed 3 successfully in removeExecutor
17/04/28 19:43:39 INFO scheduler.DAGScheduler: Shuffle files lost for executor: 3 (epoch 5)
17/04/28 19:43:39 ERROR cluster.YarnScheduler: Lost executor 3 on stack-0060.local: Container marked as failed: container_1493187723643_0007_01_000005 on host: stack-0060.local. Exit status: 1. Diagnostics: Exception from container-launch.
Container id: container_1493187723643_0007_01_000005
Exit code: 1
Stack trace: ExitCodeException exitCode=1: 
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:545)
	at org.apache.hadoop.util.Shell.run(Shell.java:456)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:722)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:211)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)


Container exited with a non-zero exit code 1

17/04/28 19:43:39 WARN scheduler.TaskSetManager: Lost task 0.0 in stage 5.0 (TID 11, stack-0060.local, executor 3): ExecutorLostFailure (executor 3 exited caused by one of the running tasks) Reason: Container marked as failed: container_1493187723643_0007_01_000005 on host: stack-0060.local. Exit status: 1. Diagnostics: Exception from container-launch.
Container id: container_1493187723643_0007_01_000005
Exit code: 1
Stack trace: ExitCodeException exitCode=1: 
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:545)
	at org.apache.hadoop.util.Shell.run(Shell.java:456)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:722)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:211)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)


Container exited with a non-zero exit code 1

17/04/28 19:43:39 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Container marked as failed: container_1493187723643_0007_01_000005 on host: stack-0060.local. Exit status: 1. Diagnostics: Exception from container-launch.
Container id: container_1493187723643_0007_01_000005
Exit code: 1
Stack trace: ExitCodeException exitCode=1: 
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:545)
	at org.apache.hadoop.util.Shell.run(Shell.java:456)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:722)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:211)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)


Container exited with a non-zero exit code 1

17/04/28 19:43:39 INFO storage.BlockManagerMaster: Removal of executor 3 requested
17/04/28 19:43:39 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asked to remove non-existent executor 3
17/04/28 19:43:39 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 3 from BlockManagerMaster.
17/04/28 19:43:40 INFO scheduler.TaskSetManager: Starting task 0.1 in stage 5.0 (TID 12, stack-0060.local, executor 1, partition 0, NODE_LOCAL, 6027 bytes)
17/04/28 19:43:40 INFO storage.BlockManagerInfo: Added broadcast_13_piece0 in memory on stack-0060.local:48293 (size: 3.4 KB, free: 323.6 MB)
17/04/28 19:43:40 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 192.168.0.243:46962
17/04/28 19:43:40 INFO spark.MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 156 bytes
17/04/28 19:43:40 INFO storage.BlockManagerInfo: Added rdd_28_0 in memory on stack-0060.local:48293 (size: 9.5 MB, free: 314.2 MB)
17/04/28 19:43:40 INFO storage.BlockManagerInfo: Added broadcast_10_piece1 in memory on stack-0060.local:48293 (size: 978.8 KB, free: 313.2 MB)
17/04/28 19:43:40 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on stack-0060.local:48293 (size: 4.0 MB, free: 309.2 MB)
17/04/28 19:43:40 INFO storage.BlockManagerInfo: Added broadcast_11_piece0 in memory on stack-0060.local:48293 (size: 24.8 KB, free: 309.2 MB)
17/04/28 19:43:40 INFO storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on stack-0060.local:48293 (size: 520.4 KB, free: 308.7 MB)
17/04/28 19:43:40 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on stack-0060.local:48293 (size: 4.0 KB, free: 308.7 MB)
17/04/28 19:43:49 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(null) (192.168.0.243:46993) with ID 4
17/04/28 19:43:49 INFO storage.BlockManagerMasterEndpoint: Registering block manager stack-0060.local:56180 with 366.3 MB RAM, BlockManagerId(4, stack-0060.local, 56180, None)
17/04/28 19:44:19 INFO scheduler.TaskSetManager: Finished task 0.1 in stage 5.0 (TID 12) in 39150 ms on stack-0060.local (executor 1) (1/1)
17/04/28 19:44:19 INFO cluster.YarnScheduler: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/04/28 19:44:19 INFO scheduler.DAGScheduler: ShuffleMapStage 5 (mapPartitionsWithIndex at Word2Vec.scala:346) finished in 46.840 s
17/04/28 19:44:19 INFO scheduler.DAGScheduler: looking for newly runnable stages
17/04/28 19:44:19 INFO scheduler.DAGScheduler: running: Set()
17/04/28 19:44:19 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 6)
17/04/28 19:44:19 INFO scheduler.DAGScheduler: failed: Set()
17/04/28 19:44:19 INFO scheduler.DAGScheduler: Submitting ResultStage 6 (ShuffledRDD[30] at reduceByKey at Word2Vec.scala:420), which has no missing parents
17/04/28 19:44:19 INFO memory.MemoryStore: Block broadcast_14 stored as values in memory (estimated size 4.4 KB, free 343.9 MB)
17/04/28 19:44:19 INFO memory.MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 2.4 KB, free 343.9 MB)
17/04/28 19:44:19 INFO storage.BlockManagerInfo: Added broadcast_14_piece0 in memory on 192.168.0.243:39783 (size: 2.4 KB, free: 360.6 MB)
17/04/28 19:44:19 INFO spark.SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:996
17/04/28 19:44:19 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (ShuffledRDD[30] at reduceByKey at Word2Vec.scala:420)
17/04/28 19:44:19 INFO cluster.YarnScheduler: Adding task set 6.0 with 1 tasks
17/04/28 19:44:19 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 6.0 (TID 13, stack-0060.local, executor 1, partition 0, NODE_LOCAL, 5762 bytes)
17/04/28 19:44:19 INFO storage.BlockManagerInfo: Added broadcast_14_piece0 in memory on stack-0060.local:48293 (size: 2.4 KB, free: 308.7 MB)
17/04/28 19:44:19 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 192.168.0.243:46962
17/04/28 19:44:19 INFO spark.MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 147 bytes
17/04/28 19:44:19 INFO storage.BlockManagerInfo: Added taskresult_13 in memory on stack-0060.local:48293 (size: 10.6 MB, free: 298.1 MB)
17/04/28 19:44:19 INFO storage.BlockManagerInfo: Removed broadcast_12_piece0 on 192.168.0.243:39783 in memory (size: 13.9 KB, free: 360.6 MB)
17/04/28 19:44:19 INFO storage.BlockManagerInfo: Removed broadcast_12_piece0 on stack-0060.local:48293 in memory (size: 13.9 KB, free: 298.1 MB)
17/04/28 19:44:19 INFO storage.BlockManagerInfo: Removed broadcast_13_piece0 on 192.168.0.243:39783 in memory (size: 3.4 KB, free: 360.6 MB)
17/04/28 19:44:19 INFO storage.BlockManagerInfo: Removed broadcast_13_piece0 on stack-0060.local:48293 in memory (size: 3.4 KB, free: 298.1 MB)
17/04/28 19:44:19 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 6.0 (TID 13) in 323 ms on stack-0060.local (executor 1) (1/1)
17/04/28 19:44:19 INFO cluster.YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool 
17/04/28 19:44:19 INFO scheduler.DAGScheduler: ResultStage 6 (collect at Word2Vec.scala:423) finished in 0.323 s
17/04/28 19:44:19 INFO scheduler.DAGScheduler: Job 3 finished: collect at Word2Vec.scala:423, took 49.148756 s
17/04/28 19:44:19 INFO storage.BlockManagerInfo: Removed taskresult_13 on stack-0060.local:48293 in memory (size: 10.6 MB, free: 308.7 MB)
17/04/28 19:44:19 INFO broadcast.TorrentBroadcast: Destroying Broadcast(10) (from destroy at Word2Vec.scala:434)
17/04/28 19:44:19 INFO storage.BlockManagerInfo: Removed broadcast_10_piece0 on 192.168.0.243:39783 in memory (size: 4.0 MB, free: 364.6 MB)
17/04/28 19:44:19 INFO broadcast.TorrentBroadcast: Destroying Broadcast(11) (from destroy at Word2Vec.scala:435)
17/04/28 19:44:19 INFO storage.BlockManagerInfo: Removed broadcast_10_piece1 on 192.168.0.243:39783 in memory (size: 978.8 KB, free: 365.6 MB)
17/04/28 19:44:19 INFO storage.BlockManagerInfo: Removed broadcast_11_piece0 on 192.168.0.243:39783 in memory (size: 24.8 KB, free: 365.6 MB)
17/04/28 19:44:19 INFO storage.BlockManagerInfo: Removed broadcast_10_piece0 on stack-0060.local:48293 in memory (size: 4.0 MB, free: 312.7 MB)
17/04/28 19:44:19 INFO storage.BlockManagerInfo: Removed broadcast_11_piece0 on stack-0060.local:48293 in memory (size: 24.8 KB, free: 312.7 MB)
17/04/28 19:44:19 INFO rdd.MapPartitionsRDD: Removing RDD 28 from persistence list
17/04/28 19:44:19 INFO storage.BlockManager: Removing RDD 28
17/04/28 19:44:19 INFO storage.BlockManagerInfo: Removed broadcast_10_piece1 on stack-0060.local:48293 in memory (size: 978.8 KB, free: 323.1 MB)
17/04/28 19:44:19 INFO broadcast.TorrentBroadcast: Destroying Broadcast(7) (from destroy at Word2Vec.scala:438)
17/04/28 19:44:19 INFO storage.BlockManagerInfo: Removed broadcast_7_piece0 on 192.168.0.243:39783 in memory (size: 4.0 KB, free: 365.6 MB)
17/04/28 19:44:19 INFO broadcast.TorrentBroadcast: Destroying Broadcast(8) (from destroy at Word2Vec.scala:439)
17/04/28 19:44:19 INFO storage.BlockManagerInfo: Removed broadcast_8_piece0 on 192.168.0.243:39783 in memory (size: 520.4 KB, free: 366.1 MB)
17/04/28 19:44:19 INFO storage.BlockManagerInfo: Removed broadcast_7_piece0 on stack-0060.local:48293 in memory (size: 4.0 KB, free: 323.1 MB)
17/04/28 19:44:19 INFO broadcast.TorrentBroadcast: Destroying Broadcast(9) (from destroy at Word2Vec.scala:440)
17/04/28 19:44:19 INFO storage.BlockManagerInfo: Removed broadcast_8_piece0 on stack-0060.local:48293 in memory (size: 520.4 KB, free: 323.6 MB)
17/04/28 19:44:19 INFO storage.BlockManagerInfo: Removed broadcast_9_piece0 on 192.168.0.243:39783 in memory (size: 145.7 KB, free: 366.3 MB)
17/04/28 19:44:19 INFO storage.BlockManagerInfo: Removed broadcast_9_piece0 on stack-0060.local:48293 in memory (size: 145.7 KB, free: 323.8 MB)
17/04/28 19:44:20 WARN netlib.BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
17/04/28 19:44:20 WARN netlib.BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
==========word2vec========
17/04/28 19:44:20 INFO storage.BlockManagerInfo: Removed broadcast_14_piece0 on 192.168.0.243:39783 in memory (size: 2.4 KB, free: 366.3 MB)
17/04/28 19:44:20 INFO storage.BlockManagerInfo: Removed broadcast_14_piece0 on stack-0060.local:48293 in memory (size: 2.4 KB, free: 323.8 MB)
17/04/28 19:44:20 INFO spark.ContextCleaner: Cleaned shuffle 2
17/04/28 19:44:21 INFO codegen.CodeGenerator: Code generated in 24.933098 ms
17/04/28 19:44:21 INFO codegen.CodeGenerator: Code generated in 21.746183 ms
+----------+--------------------+
|      word|              vector|
+----------+--------------------+
|  incident|[-0.0953257456421...|
|   serious|[-0.0498586781322...|
|    comply|[-0.0230525005608...|
|    breaks|[-0.0391842424869...|
|     mario|[0.09673014283180...|
|    boxers|[-0.0251318197697...|
| dynasties|[-0.0835031941533...|
|   sectors|[-0.2129252403974...|
| ascension|[-0.0255613345652...|
|    teresa|[0.08382143825292...|
|   gandhi.|[-0.0772333741188...|
|  embedded|[-0.0284211561083...|
|     lover|[-0.0115021616220...|
|   empire.|[-0.1946287751197...|
|     lead.|[0.20258258283138...|
| centurion|[0.09920310229063...|
|   speaker|[0.05115997791290...|
|  terrible|[0.02415386773645...|
|      lion|[-0.0177821647375...|
|expansion.|[-0.0674946531653...|
+----------+--------------------+
only showing top 20 rows

17/04/28 19:44:21 INFO codegen.CodeGenerator: Code generated in 6.346816 ms
17/04/28 19:44:21 INFO codegen.CodeGenerator: Code generated in 13.126338 ms
17/04/28 19:44:21 INFO codegen.CodeGenerator: Code generated in 12.255559 ms
17/04/28 19:44:21 INFO spark.SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
17/04/28 19:44:21 INFO scheduler.DAGScheduler: Registering RDD 34 (count at NativeMethodAccessorImpl.java:0)
17/04/28 19:44:21 INFO scheduler.DAGScheduler: Got job 4 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/04/28 19:44:21 INFO scheduler.DAGScheduler: Final stage: ResultStage 8 (count at NativeMethodAccessorImpl.java:0)
17/04/28 19:44:21 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
17/04/28 19:44:21 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 7)
17/04/28 19:44:21 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[34] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
17/04/28 19:44:21 INFO memory.MemoryStore: Block broadcast_15 stored as values in memory (estimated size 7.8 KB, free 366.0 MB)
17/04/28 19:44:21 INFO memory.MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 4.2 KB, free 366.0 MB)
17/04/28 19:44:21 INFO storage.BlockManagerInfo: Added broadcast_15_piece0 in memory on 192.168.0.243:39783 (size: 4.2 KB, free: 366.3 MB)
17/04/28 19:44:21 INFO spark.SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:996
17/04/28 19:44:21 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[34] at count at NativeMethodAccessorImpl.java:0)
17/04/28 19:44:21 INFO cluster.YarnScheduler: Adding task set 7.0 with 2 tasks
17/04/28 19:44:21 WARN scheduler.TaskSetManager: Stage 7 contains a task of very large size (113 KB). The maximum recommended task size is 100 KB.
17/04/28 19:44:21 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 7.0 (TID 14, stack-0060.local, executor 4, partition 0, PROCESS_LOCAL, 116476 bytes)
17/04/28 19:44:21 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 7.0 (TID 15, stack-0060.local, executor 1, partition 1, PROCESS_LOCAL, 116493 bytes)
17/04/28 19:44:22 INFO storage.BlockManagerInfo: Added broadcast_15_piece0 in memory on stack-0060.local:48293 (size: 4.2 KB, free: 323.8 MB)
17/04/28 19:44:22 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 7.0 (TID 15) in 220 ms on stack-0060.local (executor 1) (1/2)
17/04/28 19:44:22 INFO storage.BlockManagerInfo: Added broadcast_15_piece0 in memory on stack-0060.local:56180 (size: 4.2 KB, free: 366.3 MB)
17/04/28 19:44:22 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 7.0 (TID 14) in 1085 ms on stack-0060.local (executor 4) (2/2)
17/04/28 19:44:22 INFO cluster.YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool 
17/04/28 19:44:22 INFO scheduler.DAGScheduler: ShuffleMapStage 7 (count at NativeMethodAccessorImpl.java:0) finished in 1.084 s
17/04/28 19:44:22 INFO scheduler.DAGScheduler: looking for newly runnable stages
17/04/28 19:44:22 INFO scheduler.DAGScheduler: running: Set()
17/04/28 19:44:22 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 8)
17/04/28 19:44:22 INFO scheduler.DAGScheduler: failed: Set()
17/04/28 19:44:22 INFO scheduler.DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[37] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
17/04/28 19:44:22 INFO memory.MemoryStore: Block broadcast_16 stored as values in memory (estimated size 7.0 KB, free 366.0 MB)
17/04/28 19:44:22 INFO memory.MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 3.7 KB, free 366.0 MB)
17/04/28 19:44:22 INFO storage.BlockManagerInfo: Added broadcast_16_piece0 in memory on 192.168.0.243:39783 (size: 3.7 KB, free: 366.3 MB)
17/04/28 19:44:22 INFO spark.SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:996
17/04/28 19:44:22 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[37] at count at NativeMethodAccessorImpl.java:0)
17/04/28 19:44:22 INFO cluster.YarnScheduler: Adding task set 8.0 with 1 tasks
17/04/28 19:44:22 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 8.0 (TID 16, stack-0060.local, executor 4, partition 0, NODE_LOCAL, 5896 bytes)
17/04/28 19:44:22 INFO storage.BlockManagerInfo: Added broadcast_16_piece0 in memory on stack-0060.local:56180 (size: 3.7 KB, free: 366.3 MB)
17/04/28 19:44:23 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to 192.168.0.243:46993
17/04/28 19:44:23 INFO spark.MapOutputTrackerMaster: Size of output statuses for shuffle 3 is 163 bytes
17/04/28 19:44:23 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 8.0 (TID 16) in 130 ms on stack-0060.local (executor 4) (1/1)
17/04/28 19:44:23 INFO cluster.YarnScheduler: Removed TaskSet 8.0, whose tasks have all completed, from pool 
17/04/28 19:44:23 INFO scheduler.DAGScheduler: ResultStage 8 (count at NativeMethodAccessorImpl.java:0) finished in 0.130 s
17/04/28 19:44:23 INFO scheduler.DAGScheduler: Job 4 finished: count at NativeMethodAccessorImpl.java:0, took 1.243108 s
17/04/28 19:44:23 INFO codegen.CodeGenerator: Code generated in 17.080353 ms
word2vec size = 12983 
17/04/28 19:44:23 INFO Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
17/04/28 19:44:23 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
17/04/28 19:44:23 INFO Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
17/04/28 19:44:23 INFO Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
17/04/28 19:44:23 INFO Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
17/04/28 19:44:23 INFO spark.SparkContext: Starting job: saveAsTextFile at ReadWrite.scala:275
17/04/28 19:44:23 INFO scheduler.DAGScheduler: Got job 5 (saveAsTextFile at ReadWrite.scala:275) with 1 output partitions
17/04/28 19:44:23 INFO scheduler.DAGScheduler: Final stage: ResultStage 9 (saveAsTextFile at ReadWrite.scala:275)
17/04/28 19:44:23 INFO scheduler.DAGScheduler: Parents of final stage: List()
17/04/28 19:44:23 INFO scheduler.DAGScheduler: Missing parents: List()
17/04/28 19:44:23 INFO scheduler.DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[39] at saveAsTextFile at ReadWrite.scala:275), which has no missing parents
17/04/28 19:44:23 INFO memory.MemoryStore: Block broadcast_17 stored as values in memory (estimated size 64.2 KB, free 366.0 MB)
17/04/28 19:44:23 INFO memory.MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 22.6 KB, free 365.9 MB)
17/04/28 19:44:23 INFO storage.BlockManagerInfo: Added broadcast_17_piece0 in memory on 192.168.0.243:39783 (size: 22.6 KB, free: 366.3 MB)
17/04/28 19:44:23 INFO spark.SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:996
17/04/28 19:44:23 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[39] at saveAsTextFile at ReadWrite.scala:275)
17/04/28 19:44:23 INFO cluster.YarnScheduler: Adding task set 9.0 with 1 tasks
17/04/28 19:44:23 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 9.0 (TID 17, stack-0060.local, executor 1, partition 0, PROCESS_LOCAL, 6317 bytes)
17/04/28 19:44:23 INFO storage.BlockManagerInfo: Added broadcast_17_piece0 in memory on stack-0060.local:48293 (size: 22.6 KB, free: 323.8 MB)
17/04/28 19:44:23 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 9.0 (TID 17) in 423 ms on stack-0060.local (executor 1) (1/1)
17/04/28 19:44:23 INFO cluster.YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool 
17/04/28 19:44:23 INFO scheduler.DAGScheduler: ResultStage 9 (saveAsTextFile at ReadWrite.scala:275) finished in 0.423 s
17/04/28 19:44:23 INFO scheduler.DAGScheduler: Job 5 finished: saveAsTextFile at ReadWrite.scala:275, took 0.475502 s
17/04/28 19:44:24 INFO spark.ContextCleaner: Cleaned accumulator 560
17/04/28 19:44:24 INFO spark.ContextCleaner: Cleaned accumulator 561
17/04/28 19:44:24 INFO spark.ContextCleaner: Cleaned accumulator 562
17/04/28 19:44:24 INFO spark.ContextCleaner: Cleaned accumulator 563
17/04/28 19:44:24 INFO spark.ContextCleaner: Cleaned accumulator 564
17/04/28 19:44:24 INFO spark.ContextCleaner: Cleaned accumulator 565
17/04/28 19:44:24 INFO spark.ContextCleaner: Cleaned accumulator 566
17/04/28 19:44:24 INFO spark.ContextCleaner: Cleaned accumulator 567
17/04/28 19:44:24 INFO spark.ContextCleaner: Cleaned accumulator 568
17/04/28 19:44:24 INFO spark.ContextCleaner: Cleaned accumulator 569
17/04/28 19:44:24 INFO spark.ContextCleaner: Cleaned accumulator 570
17/04/28 19:44:24 INFO spark.ContextCleaner: Cleaned accumulator 571
17/04/28 19:44:24 INFO spark.ContextCleaner: Cleaned accumulator 572
17/04/28 19:44:24 INFO spark.ContextCleaner: Cleaned accumulator 573
17/04/28 19:44:24 INFO spark.ContextCleaner: Cleaned shuffle 3
17/04/28 19:44:24 INFO storage.BlockManagerInfo: Removed broadcast_15_piece0 on 192.168.0.243:39783 in memory (size: 4.2 KB, free: 366.3 MB)
17/04/28 19:44:24 INFO storage.BlockManagerInfo: Removed broadcast_15_piece0 on stack-0060.local:48293 in memory (size: 4.2 KB, free: 323.8 MB)
17/04/28 19:44:24 INFO storage.BlockManagerInfo: Removed broadcast_15_piece0 on stack-0060.local:56180 in memory (size: 4.2 KB, free: 366.3 MB)
17/04/28 19:44:24 INFO storage.BlockManagerInfo: Removed broadcast_16_piece0 on 192.168.0.243:39783 in memory (size: 3.7 KB, free: 366.3 MB)
17/04/28 19:44:24 INFO storage.BlockManagerInfo: Removed broadcast_16_piece0 on stack-0060.local:56180 in memory (size: 3.7 KB, free: 366.3 MB)
17/04/28 19:44:24 INFO storage.BlockManagerInfo: Removed broadcast_17_piece0 on 192.168.0.243:39783 in memory (size: 22.6 KB, free: 366.3 MB)
17/04/28 19:44:24 INFO storage.BlockManagerInfo: Removed broadcast_17_piece0 on stack-0060.local:48293 in memory (size: 22.6 KB, free: 323.8 MB)
17/04/28 19:44:24 INFO spark.ContextCleaner: Cleaned shuffle 1
17/04/28 19:44:24 INFO storage.BlockManager: Removing RDD 28
17/04/28 19:44:24 INFO spark.ContextCleaner: Cleaned RDD 28
17/04/28 19:44:24 INFO spark.ContextCleaner: Cleaned accumulator 103
17/04/28 19:44:24 INFO parquet.ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
17/04/28 19:44:24 INFO codegen.CodeGenerator: Code generated in 33.100385 ms
17/04/28 19:44:24 INFO datasources.SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/04/28 19:44:24 INFO datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/04/28 19:44:24 INFO spark.SparkContext: Starting job: parquet at Word2Vec.scala:314
17/04/28 19:44:24 INFO scheduler.DAGScheduler: Registering RDD 42 (parquet at Word2Vec.scala:314)
17/04/28 19:44:24 INFO scheduler.DAGScheduler: Got job 6 (parquet at Word2Vec.scala:314) with 1 output partitions
17/04/28 19:44:24 INFO scheduler.DAGScheduler: Final stage: ResultStage 11 (parquet at Word2Vec.scala:314)
17/04/28 19:44:24 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
17/04/28 19:44:24 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 10)
17/04/28 19:44:24 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[42] at parquet at Word2Vec.scala:314), which has no missing parents
17/04/28 19:44:24 INFO memory.MemoryStore: Block broadcast_18 stored as values in memory (estimated size 5.0 KB, free 366.0 MB)
17/04/28 19:44:24 INFO memory.MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 3.0 KB, free 366.0 MB)
17/04/28 19:44:24 INFO storage.BlockManagerInfo: Added broadcast_18_piece0 in memory on 192.168.0.243:39783 (size: 3.0 KB, free: 366.3 MB)
17/04/28 19:44:24 INFO spark.SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:996
17/04/28 19:44:24 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[42] at parquet at Word2Vec.scala:314)
17/04/28 19:44:24 INFO cluster.YarnScheduler: Adding task set 10.0 with 1 tasks
17/04/28 19:44:24 WARN scheduler.TaskSetManager: Stage 10 contains a task of very large size (5545 KB). The maximum recommended task size is 100 KB.
17/04/28 19:44:24 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 10.0 (TID 18, stack-0060.local, executor 1, partition 0, PROCESS_LOCAL, 5678210 bytes)
17/04/28 19:44:24 INFO spark.ContextCleaner: Cleaned accumulator 742
17/04/28 19:44:25 INFO storage.BlockManagerInfo: Added broadcast_18_piece0 in memory on stack-0060.local:48293 (size: 3.0 KB, free: 323.8 MB)
17/04/28 19:44:25 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 10.0 (TID 18) in 197 ms on stack-0060.local (executor 1) (1/1)
17/04/28 19:44:25 INFO cluster.YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool 
17/04/28 19:44:25 INFO scheduler.DAGScheduler: ShuffleMapStage 10 (parquet at Word2Vec.scala:314) finished in 0.198 s
17/04/28 19:44:25 INFO scheduler.DAGScheduler: looking for newly runnable stages
17/04/28 19:44:25 INFO scheduler.DAGScheduler: running: Set()
17/04/28 19:44:25 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 11)
17/04/28 19:44:25 INFO scheduler.DAGScheduler: failed: Set()
17/04/28 19:44:25 INFO scheduler.DAGScheduler: Submitting ResultStage 11 (ShuffledRowRDD[43] at parquet at Word2Vec.scala:314), which has no missing parents
17/04/28 19:44:25 INFO memory.MemoryStore: Block broadcast_19 stored as values in memory (estimated size 69.7 KB, free 366.0 MB)
17/04/28 19:44:25 INFO memory.MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 26.2 KB, free 365.9 MB)
17/04/28 19:44:25 INFO storage.BlockManagerInfo: Added broadcast_19_piece0 in memory on 192.168.0.243:39783 (size: 26.2 KB, free: 366.3 MB)
17/04/28 19:44:25 INFO spark.SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:996
17/04/28 19:44:25 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (ShuffledRowRDD[43] at parquet at Word2Vec.scala:314)
17/04/28 19:44:25 INFO cluster.YarnScheduler: Adding task set 11.0 with 1 tasks
17/04/28 19:44:25 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 11.0 (TID 19, stack-0060.local, executor 4, partition 0, NODE_LOCAL, 5904 bytes)
17/04/28 19:44:25 INFO storage.BlockManagerInfo: Added broadcast_19_piece0 in memory on stack-0060.local:56180 (size: 26.2 KB, free: 366.3 MB)
17/04/28 19:44:25 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 4 to 192.168.0.243:46993
17/04/28 19:44:25 INFO spark.MapOutputTrackerMaster: Size of output statuses for shuffle 4 is 147 bytes
17/04/28 19:44:27 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Disabling executor 4.
17/04/28 19:44:27 INFO scheduler.DAGScheduler: Executor lost: 4 (epoch 10)
17/04/28 19:44:27 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 4 from BlockManagerMaster.
17/04/28 19:44:27 INFO storage.BlockManagerMasterEndpoint: Removing block manager BlockManagerId(4, stack-0060.local, 56180, None)
17/04/28 19:44:27 INFO storage.BlockManagerMaster: Removed 4 successfully in removeExecutor
17/04/28 19:44:27 INFO scheduler.DAGScheduler: Shuffle files lost for executor: 4 (epoch 10)
17/04/28 19:44:28 ERROR cluster.YarnScheduler: Lost executor 4 on stack-0060.local: Container marked as failed: container_1493187723643_0007_01_000006 on host: stack-0060.local. Exit status: 1. Diagnostics: Exception from container-launch.
Container id: container_1493187723643_0007_01_000006
Exit code: 1
Stack trace: ExitCodeException exitCode=1: 
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:545)
	at org.apache.hadoop.util.Shell.run(Shell.java:456)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:722)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:211)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)


Container exited with a non-zero exit code 1

17/04/28 19:44:28 WARN scheduler.TaskSetManager: Lost task 0.0 in stage 11.0 (TID 19, stack-0060.local, executor 4): ExecutorLostFailure (executor 4 exited caused by one of the running tasks) Reason: Container marked as failed: container_1493187723643_0007_01_000006 on host: stack-0060.local. Exit status: 1. Diagnostics: Exception from container-launch.
Container id: container_1493187723643_0007_01_000006
Exit code: 1
Stack trace: ExitCodeException exitCode=1: 
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:545)
	at org.apache.hadoop.util.Shell.run(Shell.java:456)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:722)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:211)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)


Container exited with a non-zero exit code 1

17/04/28 19:44:28 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Container marked as failed: container_1493187723643_0007_01_000006 on host: stack-0060.local. Exit status: 1. Diagnostics: Exception from container-launch.
Container id: container_1493187723643_0007_01_000006
Exit code: 1
Stack trace: ExitCodeException exitCode=1: 
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:545)
	at org.apache.hadoop.util.Shell.run(Shell.java:456)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:722)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:211)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)


Container exited with a non-zero exit code 1

17/04/28 19:44:28 INFO storage.BlockManagerMaster: Removal of executor 4 requested
17/04/28 19:44:28 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 4 from BlockManagerMaster.
17/04/28 19:44:28 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asked to remove non-existent executor 4
17/04/28 19:44:29 INFO scheduler.TaskSetManager: Starting task 0.1 in stage 11.0 (TID 20, stack-0060.local, executor 1, partition 0, NODE_LOCAL, 5904 bytes)
17/04/28 19:44:29 INFO storage.BlockManagerInfo: Added broadcast_19_piece0 in memory on stack-0060.local:48293 (size: 26.2 KB, free: 323.8 MB)
17/04/28 19:44:29 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 4 to 192.168.0.243:46962
17/04/28 19:44:29 INFO spark.MapOutputTrackerMaster: Size of output statuses for shuffle 4 is 147 bytes
17/04/28 19:44:31 INFO scheduler.DAGScheduler: ResultStage 11 (parquet at Word2Vec.scala:314) finished in 6.482 s
17/04/28 19:44:31 INFO scheduler.DAGScheduler: Job 6 finished: parquet at Word2Vec.scala:314, took 6.714145 s
17/04/28 19:44:31 INFO scheduler.TaskSetManager: Finished task 0.1 in stage 11.0 (TID 20) in 2191 ms on stack-0060.local (executor 1) (1/1)
17/04/28 19:44:31 INFO cluster.YarnScheduler: Removed TaskSet 11.0, whose tasks have all completed, from pool 
17/04/28 19:44:31 INFO datasources.FileFormatWriter: Job null committed.
17/04/28 19:44:34 INFO storage.BlockManagerInfo: Removed broadcast_19_piece0 on 192.168.0.243:39783 in memory (size: 26.2 KB, free: 366.3 MB)
17/04/28 19:44:34 INFO storage.BlockManagerInfo: Removed broadcast_19_piece0 on stack-0060.local:48293 in memory (size: 26.2 KB, free: 323.8 MB)
17/04/28 19:44:35 WARN amfilter.AmIpFilter: Could not find proxy-user cookie, so user will not be set
create-word2vec-model.py
Got App ID. AppID = application_1493187723643_0007
17/04/28 19:44:35 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Disabling executor 1.
17/04/28 19:44:35 INFO scheduler.DAGScheduler: Executor lost: 1 (epoch 11)
17/04/28 19:44:35 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 1 from BlockManagerMaster.
17/04/28 19:44:35 INFO storage.BlockManagerMasterEndpoint: Removing block manager BlockManagerId(1, stack-0060.local, 48293, None)
17/04/28 19:44:35 INFO storage.BlockManagerMaster: Removed 1 successfully in removeExecutor
17/04/28 19:44:35 INFO scheduler.DAGScheduler: Shuffle files lost for executor: 1 (epoch 11)
17/04/28 19:44:35 WARN amfilter.AmIpFilter: Could not find proxy-user cookie, so user will not be set
17/04/28 19:44:35 ERROR client.TransportClient: Failed to send RPC 7079802999494308511 to /192.168.0.243:46957: java.nio.channels.ClosedChannelException
java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
17/04/28 19:44:35 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Attempted to get executor loss reason for executor id 1 at RPC address 192.168.0.243:46962, but got no response. Marking as slave lost.
java.io.IOException: Failed to send RPC 7079802999494308511 to /192.168.0.243:46957: java.nio.channels.ClosedChannelException
	at org.apache.spark.network.client.TransportClient$3.operationComplete(TransportClient.java:249)
	at org.apache.spark.network.client.TransportClient$3.operationComplete(TransportClient.java:233)
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:514)
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:488)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:427)
	at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:129)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetFailure(AbstractChannel.java:852)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:738)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1251)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:743)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:735)
	at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:36)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1072)
	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1126)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1061)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:408)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:455)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:140)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
17/04/28 19:44:35 ERROR cluster.YarnScheduler: Lost executor 1 on stack-0060.local: Slave lost
17/04/28 19:44:36 WARN amfilter.AmIpFilter: Could not find proxy-user cookie, so user will not be set
17/04/28 19:44:36 WARN amfilter.AmIpFilter: Could not find proxy-user cookie, so user will not be set
17/04/28 19:44:36 INFO server.ServerConnector: Stopped ServerConnector@30c6115f{HTTP/1.1}{0.0.0.0:4040}
17/04/28 19:44:36 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@a7072fd{/stages/stage/kill,null,UNAVAILABLE}
17/04/28 19:44:36 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@52f7cbf9{/jobs/job/kill,null,UNAVAILABLE}
17/04/28 19:44:36 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@2d97f391{/api,null,UNAVAILABLE}
17/04/28 19:44:36 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@65ed0ba6{/,null,UNAVAILABLE}
17/04/28 19:44:36 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@51753509{/static,null,UNAVAILABLE}
17/04/28 19:44:36 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@1619372c{/executors/threadDump/json,null,UNAVAILABLE}
17/04/28 19:44:36 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@cd96b63{/executors/threadDump,null,UNAVAILABLE}
17/04/28 19:44:36 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@76b98152{/executors/json,null,UNAVAILABLE}
17/04/28 19:44:36 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@1493d9b3{/executors,null,UNAVAILABLE}
17/04/28 19:44:36 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@278904b4{/environment/json,null,UNAVAILABLE}
17/04/28 19:44:36 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@56f7d03f{/environment,null,UNAVAILABLE}
17/04/28 19:44:36 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@5f4991a0{/storage/rdd/json,null,UNAVAILABLE}
17/04/28 19:44:36 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@15603546{/storage/rdd,null,UNAVAILABLE}
17/04/28 19:44:36 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@2cf530f1{/storage/json,null,UNAVAILABLE}
17/04/28 19:44:36 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@3eb05e26{/storage,null,UNAVAILABLE}
17/04/28 19:44:36 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@1ae91dff{/stages/pool/json,null,UNAVAILABLE}
17/04/28 19:44:36 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@30a8cfe6{/stages/pool,null,UNAVAILABLE}
17/04/28 19:44:36 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@267e5798{/stages/stage/json,null,UNAVAILABLE}
17/04/28 19:44:36 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@1edd9ed{/stages/stage,null,UNAVAILABLE}
17/04/28 19:44:36 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@730f8cef{/stages/json,null,UNAVAILABLE}
17/04/28 19:44:36 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@3d373366{/stages,null,UNAVAILABLE}
17/04/28 19:44:36 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@67945c4a{/jobs/job/json,null,UNAVAILABLE}
17/04/28 19:44:36 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@3b7e66e1{/jobs/job,null,UNAVAILABLE}
17/04/28 19:44:36 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@7463ab39{/jobs/json,null,UNAVAILABLE}
17/04/28 19:44:36 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@66019ed8{/jobs,null,UNAVAILABLE}
17/04/28 19:44:36 INFO ui.SparkUI: Stopped Spark web UI at http://192.168.0.243:4040
17/04/28 19:44:36 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread
17/04/28 19:44:36 ERROR client.TransportClient: Failed to send RPC 7220338651568666243 to /192.168.0.243:46957: java.nio.channels.ClosedChannelException
java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
17/04/28 19:44:36 ERROR cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Sending RequestExecutors(0,0,Map()) to AM was unsuccessful
java.io.IOException: Failed to send RPC 7220338651568666243 to /192.168.0.243:46957: java.nio.channels.ClosedChannelException
	at org.apache.spark.network.client.TransportClient$3.operationComplete(TransportClient.java:249)
	at org.apache.spark.network.client.TransportClient$3.operationComplete(TransportClient.java:233)
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:514)
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:488)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:427)
	at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:129)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetFailure(AbstractChannel.java:852)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:738)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1251)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:743)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:735)
	at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:36)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1072)
	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1126)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1061)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:408)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:455)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:140)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
17/04/28 19:44:36 INFO cluster.SchedulerExtensionServices: Stopping SchedulerExtensionServices
(serviceOption=None,
 services=List(),
 started=false)
17/04/28 19:44:36 ERROR util.Utils: Uncaught exception in thread Thread-3
org.apache.spark.SparkException: Exception thrown in awaitResult
	at org.apache.spark.rpc.RpcTimeout$$anonfun$1.applyOrElse(RpcTimeout.scala:77)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$1.applyOrElse(RpcTimeout.scala:75)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:59)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:59)
	at scala.PartialFunction$OrElse.apply(PartialFunction.scala:167)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:83)
	at org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend.requestTotalExecutors(CoarseGrainedSchedulerBackend.scala:512)
	at org.apache.spark.scheduler.cluster.YarnSchedulerBackend.stop(YarnSchedulerBackend.scala:93)
	at org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend.stop(YarnClientSchedulerBackend.scala:151)
	at org.apache.spark.scheduler.TaskSchedulerImpl.stop(TaskSchedulerImpl.scala:467)
	at org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:1588)
	at org.apache.spark.SparkContext$$anonfun$stop$8.apply$mcV$sp(SparkContext.scala:1826)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1283)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1825)
	at org.apache.spark.api.java.JavaSparkContext.stop(JavaSparkContext.scala:654)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:280)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:214)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: Failed to send RPC 7220338651568666243 to /192.168.0.243:46957: java.nio.channels.ClosedChannelException
	at org.apache.spark.network.client.TransportClient$3.operationComplete(TransportClient.java:249)
	at org.apache.spark.network.client.TransportClient$3.operationComplete(TransportClient.java:233)
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:514)
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:488)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:427)
	at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:129)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetFailure(AbstractChannel.java:852)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:738)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1251)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:743)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:735)
	at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:36)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1072)
	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1126)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1061)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:408)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:455)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:140)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
17/04/28 19:44:36 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/04/28 19:44:36 INFO memory.MemoryStore: MemoryStore cleared
17/04/28 19:44:36 INFO storage.BlockManager: BlockManager stopped
17/04/28 19:44:36 INFO storage.BlockManagerMaster: BlockManagerMaster stopped
17/04/28 19:44:36 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/04/28 19:44:36 INFO spark.SparkContext: Successfully stopped SparkContext
17/04/28 19:44:37 INFO util.ShutdownHookManager: Shutdown hook called
17/04/28 19:44:37 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-a14ff61a-ee4a-43c0-9753-2e5df4ddd78e
17/04/28 19:44:37 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-a14ff61a-ee4a-43c0-9753-2e5df4ddd78e/pyspark-1716c649-748b-4dc5-8d4b-ab577b7252fc
